<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>CloudWeGo – CloudWeGo</title><link>/zh/</link><description>Recent content on CloudWeGo</description><generator>Hugo -- gohugo.io</generator><atom:link href="/zh/index.xml" rel="self" type="application/rss+xml"/><item><title>Blog: Kitex v0.3.2 版本发布</title><link>/zh/blog/2022/06/02/kitex-v0.3.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Thu, 02 Jun 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/06/02/kitex-v0.3.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="feature">Feature&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/473">#473&lt;/a>] 功能 (grpc): 为 Kitex gRPC unary 模式增加短连接功能。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/431">#431&lt;/a>] 功能 (limiter):
&lt;ol>
&lt;li>支持自定义的限流实现，接口增加了请求参数的传递；&lt;/li>
&lt;li>修复多路复用场景下 Server 的 QPS 限流器问题，添加基于 OnMessage 的限流；&lt;/li>
&lt;li>调整默认的限流生效时机，只有使用框架 QPS 限流且非多路复用的场景下，才使用基于 OnRead 的限流。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;/ul>
&lt;h2 id="optimize">Optimize&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/465">#465&lt;/a>] 优化 (ttheader): Client 端在 TTHeader 解码结束后赋值 Remote Address (用于 Proxy 场景请求失败时获取对端地址)。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/466">#466&lt;/a>] 优化 (mux): 连接多路复用场景的 ErrReadTimeout 用 ErrRPCTimeout 封装返回。Proxy 场景请求失败时获取对端地址)。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/425">#425&lt;/a>] 优化 (limiter): 优化限流实现，保证第一秒的 Tokens 不会大幅超过限制。&lt;/li>
&lt;/ul>
&lt;h2 id="bugfix">Bugfix&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/485">#485&lt;/a>] 修复 (grpc): 修复 grpc 内不恰当的 int 类型转换。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/474">#474&lt;/a>] 修复 (trans): 在 detection handler 中增加检测。当 OnInactive 比 OnActive 先发生，或者 OnActive 返回 error 时，防止空指针 panic。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/445">#445&lt;/a>] 修复 (retry):
&lt;ol>
&lt;li>修复重试中 &lt;code>callTimes&lt;/code> 字段的 race 问题；&lt;/li>
&lt;li>修复 &lt;code>rpcStats&lt;/code> 中一些字段的 race 问题。&lt;/li>
&lt;/ol>
&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/471">#471&lt;/a>] 修复 (retry): 修复在 backup request 中的一个 race 问题。&lt;/li>
&lt;/ul>
&lt;h2 id="test">Test&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/404">#404&lt;/a>] test: 增加 pkg/retry 的单测。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/439">#439&lt;/a>, &lt;a href="https://github.com/cloudwego/kitex/pull/472">#472&lt;/a>] test: 增加 pkg/remote/remotecli 的单测。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/462">#462&lt;/a>, &lt;a href="https://github.com/cloudwego/kitex/pull/457">#457&lt;/a>] test: 增加 pkg/remote/trans/nphttp2/grpc 的单测。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/420">#420&lt;/a>] test: 增加 pkg/remote/trans/nphttp2 的单测。&lt;/li>
&lt;/ul>
&lt;h2 id="refactor">Refactor&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/464">#464&lt;/a>] refactor (ttheader): 修改 Kitex Protobuf 在 TTHeader 中的 protocolID，同时保证该变更与低版本的兼容性。&lt;/li>
&lt;/ul>
&lt;h2 id="chore">Chore&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/453">#453&lt;/a>, &lt;a href="https://github.com/cloudwego/kitex/pull/475">#475&lt;/a>] chore: 更新 netpoll 和 bytedance/gopkg 的版本。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/458">#458&lt;/a>] chore: 修复了 reviewdog 失效的问题与 fork pr 单测的问题。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/454">#454&lt;/a>] chore: 现在的 CI 受限于 github runner 的性能经常会失败，尝试改成 self-hosted runner 来提升性能。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/449">#449&lt;/a>] chore: 更新 issue template，修改为更适合 Kitex 项目的问题模板。&lt;/li>
&lt;/ul>
&lt;h2 id="style">Style&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/486">#486&lt;/a>] style (trans): 为 detection trans handler 增加注释信息。&lt;/li>
&lt;/ul>
&lt;h2 id="docs">Docs&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/482">#482&lt;/a>] docs: 在 Readme 中增加 FAQ 链接。&lt;/li>
&lt;/ul>
&lt;h2 id="dependency-change">Dependency Change&lt;/h2>
&lt;ul>
&lt;li>github.com/cloudwego/netpoll: v0.2.2 -&amp;gt; v0.2.4&lt;/li>
&lt;/ul></description></item><item><title>Blog: 从 CloudWeGo 谈云原生时代的微服务与开源</title><link>/zh/blog/2022/05/26/%E4%BB%8E-cloudwego-%E8%B0%88%E4%BA%91%E5%8E%9F%E7%94%9F%E6%97%B6%E4%BB%A3%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%8E%E5%BC%80%E6%BA%90/</link><pubDate>Thu, 26 May 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/05/26/%E4%BB%8E-cloudwego-%E8%B0%88%E4%BA%91%E5%8E%9F%E7%94%9F%E6%97%B6%E4%BB%A3%E7%9A%84%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%8E%E5%BC%80%E6%BA%90/</guid><description>
&lt;h1 id="从-cloudwego-谈云原生时代的微服务与开源">从 CloudWeGo 谈云原生时代的微服务与开源&lt;/h1>
&lt;blockquote>
&lt;p>本文整理自罗广明在 DIVE 全球基础软件创新大会 2022 的演讲分享，主题为《从 CloudWeGo 谈云原生时代的微服务与开源》。&lt;/p>
&lt;/blockquote>
&lt;h2 id="01-项目创造的思考与哲学">&lt;strong>01 项目创造的思考与哲学&lt;/strong>&lt;/h2>
&lt;p>我们团队经常会被人问到，你们为什么创造一个新的项目？我认为这是一个哲学问题。&lt;/p>
&lt;p>纵观整个开源社区，每个时间段都会有各种各样的项目被重复地创造出来，这其中的大部分项目很快便销声匿迹了，只有一部分项目能够存活下来。当旁观者看到这样一番景象时，渐渐地，越来越多的人停留于项目搜寻，而放弃了成为项目创作者的机会。久而久之，我们开始忧虑下一代是否还会有新的项目可以使用？难道未来在同一领域，一个项目就能统一整个市场？&lt;/p>
&lt;p>其实，在程序员的世界里，参考旧的项目来创造新的项目一点都不可耻。创造不仅意味着思考、权衡与设计，更需要我们贡献项目的特殊与差异。这其中涌现了很多后起之秀，正是他们促成了开源社区的多样性。“每一行代码都是一次精心的设计”是我们对优秀创造者的最佳赞誉。而一项优秀的代码设计往往包含两个最基本的特性：正确性和可维护性。同时，这两种特性恰恰又对应了两种不同的人格。&lt;/p>
&lt;p>第一种人格，设计者与实现者，其驾驭是相对简单的，只要功能实现，通过测试，运行正确就算完成了。然而，第二种人格，阅读者和维护者，却要求更高的代码质量，更明晰的代码结构和更好的扩展性。只有同时具备这两种人格，开发者才能游刃有余地创造出一个优秀的项目。&lt;/p>
&lt;p>优秀的项目被创造出来意味着什么呢？千千万万的用户可以评估并且使用它。这也从侧面表明了开源本身可以避免更多项目被重复地创造出来。&lt;/p>
&lt;h2 id="02-cloudwego-简介">&lt;strong>02 CloudWeGo 简介&lt;/strong>&lt;/h2>
&lt;p>CloudWeGo 是字节跳动基础架构团队开源出来的项目，它是一套可快速构建&lt;strong>企业级&lt;/strong>云原生架构的中间件集合，它专注于微服务通信与治理，具备&lt;strong>高性能&lt;/strong>、&lt;strong>可扩展&lt;/strong>、&lt;strong>高可靠&lt;/strong>的特点，且关注&lt;strong>易用性&lt;/strong>。&lt;/p>
&lt;p>CloudWeGo 在第一阶段开源了四个项目：&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/cloudwego/kitex">&lt;strong>Kitex&lt;/strong>&lt;/a>：高性能、强可扩展的 Golang RPC 框架&lt;/li>
&lt;li>&lt;a href="https://github.com/cloudwego/netpoll">&lt;strong>Netpoll&lt;/strong>&lt;/a>：高性能、I/O 非阻塞、专注于 RPC 场景的网络框架&lt;/li>
&lt;li>&lt;a href="https://github.com/cloudwego/thriftgo">&lt;strong>Thriftgo&lt;/strong>&lt;/a>：Golang 实现的 thrift 编译器，支持插件机制和语义检查&lt;/li>
&lt;li>&lt;a href="https://github.com/cloudwego/netpoll-http2">&lt;strong>Netpoll-http2&lt;/strong>&lt;/a>：基于 Netpoll 的 HTTP/2 实现&lt;/li>
&lt;/ul>
&lt;p>除了这几个主要项目外，CloudWeGo 紧随其后陆续开源了 &lt;a href="https://github.com/cloudwego/kitex-benchmark">&lt;strong>Kitex-benchmark&lt;/strong>&lt;/a>、&lt;a href="https://github.com/cloudwego/netpoll-benchmark">&lt;strong>Netpoll-benchmark&lt;/strong>&lt;/a>、&lt;a href="https://github.com/cloudwego/thrift-gen-validator">&lt;strong>Thrift-gen-validator&lt;/strong>&lt;/a>、&lt;a href="https://github.com/cloudwego/kitex-examples">&lt;strong>Kitex-examples&lt;/strong>&lt;/a> 、&lt;a href="https://github.com/cloudwego/netpoll-examples">&lt;strong>Netpoll-examples&lt;/strong>&lt;/a>等项目。&lt;/p>
&lt;p>鉴于文章篇幅有限，下文将重点介绍 CloudWeGo 核心项目 Kitex。&lt;/p>
&lt;p>从&lt;strong>演进历史&lt;/strong>来看，2014 年，字节跳动技术团队引入 Golang 解决长连接推送业务面临的高并发问题，两年后，内部技术团队基于 Golang 推出了一个名为 Kite 的框架，同时对开源项目 Gin 做了一层很薄的封装，推出了 Ginex。这两个框架极大推动了 Golang 在公司内部的应用。此后，围绕性能和可扩展性设计，字节跳动重构 Kite，并在次年 10 月完成并发布Kitex，投入到内部应用中。据悉，截至 2021 年 9 月，线上有 3w+ 微服务使用 Kitex，大部分服务迁移新框架后可以收获 CPU 和延迟上的收益。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Framework.PNG" alt="image">&lt;/p>
&lt;p>从&lt;strong>架构&lt;/strong>上看，Kitex 主要分为两部分。其中 Kitex Core 是它的的主干逻辑，定义了框架的层次结构、接口，还有接口的默认实现。最上面 Client 和 Server 是对用户暴露的，包含 Option 配置以及其初始化的逻辑；中间的 Modules 模块是框架治理层面的功能模块和交互元信息，而 Remote 模块是与对端交互的模块，包括编解码和网络通信。另一部分 Kitex Tool 则是对应生成代码相关的实现，生成代码工具就是编译这个包得到的，里面包括 IDL 解析、校验、代码生成、插件支持、自更新等。&lt;/p>
&lt;p>从&lt;strong>功能与特性&lt;/strong>这两个角度来看，主要可以分为以下七个方面：&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Functions_Features.PNG" alt="image">&lt;/p>
&lt;ul>
&lt;li>&lt;strong>高性能&lt;/strong>：网络传输模块 Kitex 默认集成了自研的网络库 Netpoll，性能相较使用 go net 有显著优势；除了网络库带来的性能收益，Kitex 对 Thrift 编解码也做了深度优化。关于性能数据可参考 &lt;a href="https://github.com/cloudwego/kitex-benchmark">kitex-benchmark&lt;/a>。&lt;/li>
&lt;li>&lt;strong>扩展性&lt;/strong>：Kitex 设计上做了模块划分，提供了较多的扩展接口以及默认的扩展实现，使用者也可以根据需要自行定制扩展，更多扩展能力参见 CloudWeGo &lt;a href="https://www.cloudwego.io/zh/docs/kitex/tutorials/framework-exten/">官网文档&lt;/a>。Kitex 也并未耦合 Netpoll，开发者也可以选择其它网络库扩展使用。&lt;/li>
&lt;li>&lt;strong>消息协议&lt;/strong>：RPC 消息协议默认支持 Thrift、Kitex Protobuf、gRPC。Thrift 支持 Buffered 和 Framed 二进制协议；Kitex Protobuf 是 Kitex 自定义的 Protobuf 消息协议，协议格式类似 Thrift；gRPC 是对 gRPC 消息协议的支持，可以与 gRPC 互通。除此之外，使用者也可以扩展自己的消息协议。&lt;/li>
&lt;li>&lt;strong>传输协议&lt;/strong>：传输协议封装消息协议进行 RPC 互通，传输协议可以额外透传元信息，用于服务治理，Kitex 支持的传输协议有 TTHeader、HTTP2。TTHeader 可以和 Thrift、Kitex Protobuf 结合使用；HTTP2 目前主要是结合 gRPC 协议使用，后续也会支持 Thrift。&lt;/li>
&lt;li>&lt;strong>多消息类型&lt;/strong>：支持 PingPong、Oneway、双向 Streaming。其中 Oneway 目前只对 Thrift 协议支持，双向 Streaming 只对 gRPC 支持，后续会考虑支持 Thrift 的双向 Streaming。&lt;/li>
&lt;li>&lt;strong>服务治理&lt;/strong>：支持服务注册/发现、负载均衡、熔断、限流、重试、监控、链路跟踪、日志、诊断等服务治理模块，大部分均已提供默认扩展，使用者可选择集成。&lt;/li>
&lt;li>&lt;strong>Kitex 内置代码生成工具，可支持生成 Thrift、Protobuf 以及脚手架代码&lt;/strong>。原生的 Thrift 代码由本次一起开源的 Thriftgo 生成，Kitex 对 Thrift 的优化由 Kitex Tool 作为插件支持。Protobuf 代码由 Kitex 作为官方 protoc 插件生成 ，目前暂未单独支持 Protobuf IDL 的解析和代码生成。&lt;/li>
&lt;/ul>
&lt;p>简单总结一下，CloudWeGo 不仅仅是一个开源的项目，也是一个真实的、超大规模的&lt;strong>企业级&lt;/strong>最佳实践。它源自企业，所以天生就适合在企业内部落地；它源自开源，最终也拥抱了开源，从 Go 基础库，到 Go 网络库和 Thrift 编译器，再到上层的服务框架，以及框架拥有的所有企业级治理能力，均对外开放开源。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Enterprise.PNG" alt="image">&lt;/p>
&lt;h2 id="03-cloudwego-的微服务治理">&lt;strong>03 CloudWeGo 的微服务治理&lt;/strong>&lt;/h2>
&lt;p>微服务架构是当前软件开发领域的技术热点。大系统终究会拆解成小系统，“合久必分，分而治之”，传统行业的系统架构大多都是庞大的单体架构，微服务是架构发展过程中一个非常自然的演变状态。&lt;/p>
&lt;p>那么，什么是微服务治理呢？众说纷纭，业界没有达成一个共识。广义上，服务治理关注服务生命周期相关要素，包括服务的架构设计、应用发布、注册发现、流量管理，监控与可观测性、故障定位、安全性等；又或将其分为架构治理、研发治理、测试治理、运维治理、管理治理。狭义上，服务治理技术包括服务注册与发现、可观测性、流量管理、安全、控制。后续主要是从狭义上服务治理的角度出发，展开介绍 CloudWeGo-Kitex 相关的思考和探索。&lt;/p>
&lt;h3 id="服务注册与发现">&lt;strong>服务注册与发现&lt;/strong>&lt;/h3>
&lt;p>Kitex 并不提供默认的服务注册发现，体现了框架的&lt;strong>中立&lt;/strong>特征。Kitex 支持自定义注册模块和发现模块，使用者可自行扩展集成其他注册中心和服务发现实现，该扩展分别定义在 Pkg/Registry 和 Pkg/Discovery 下。&lt;/p>
&lt;p>Kitex 服务注册扩展接口如下所示，更多详情可以查看官网框架扩展 -&amp;gt; &lt;a href="https://www.cloudwego.io/zh/docs/kitex/tutorials/framework-exten/registry/">服务注册扩展&lt;/a>。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Service_registry.png" alt="image">&lt;/p>
&lt;p>Kitex 服务发现扩展接口如下所示，更多详情可以查看官网框架扩展 -&amp;gt; &lt;a href="https://www.cloudwego.io/zh/docs/kitex/tutorials/framework-exten/service_discovery/">服务发现扩展&lt;/a>。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Service_discovery.png" alt="image">&lt;/p>
&lt;p>截止日前，Kitex 已经通过社区开发者的支持，完成了 ETCD、ZooKeeper、Eureka、Consul、Nacos、Polaris 多种服务发现模式，当然也支持 DNS 解析以及 Static IP 直连访问模式，建立起了强大且完备的社区生态，供用户按需灵活选用。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Community_ecology.PNG" alt="image">&lt;/p>
&lt;p>特别鸣谢 @li-jin-gou @liu-song @baiyutang @duduainankai @horizonzy @Hanson 等几位社区贡献者对上述服务发现扩展库的实现与支持。更多代码详情可以查看 &lt;a href="https://github.com/kitex-contrib">https://github.com/kitex-contrib&lt;/a> 。&lt;/p>
&lt;h3 id="熔断">&lt;strong>熔断&lt;/strong>&lt;/h3>
&lt;p>前面介绍了 Kitex 服务注册与发现机制，这一点对于业务接入框架非常重要，缺少这一环节微服务之间无法实现互通。那么熔断对于微服务有什么作用呢？&lt;/p>
&lt;p>在微服务进行 RPC 调用时，下游服务难免会出错，当下游出现问题时，如果上游继续对其进行调用，既妨碍了下游的恢复，也浪费了上游的资源。为了解决这个问题，可以设置一些动态开关，当下游出错时，手动的关闭对下游的调用，然而更好的办法是使用熔断器，自动解决这个问题。&lt;/p>
&lt;p>Kitex 提供了熔断器的实现，但是没有默认开启，需要用户主动开启后即可使用。&lt;/p>
&lt;p>Kitex 大部分服务治理模块都是通过 Middleware 集成，熔断也是一样。Kitex 提供了一套 CBSuite，封装了服务粒度的熔断器和实例粒度的熔断器。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>服务粒度熔断&lt;/strong>：按照服务粒度进行熔断统计，通过 WithMiddleware 添加。服务粒度的具体划分取决于 Circuit Breaker Key，即熔断统计的 Key，初始化 CBSuite 时需要传入 &lt;strong>GenServiceCBKeyFunc&lt;/strong>。默认提供的是 &lt;code>circuitbreaker.RPCInfo2Key&lt;/code>，该 Key 的格式是 &lt;code>fromServiceName/toServiceName/method&lt;/code>，即按照方法级别的异常做熔断统计。&lt;/li>
&lt;li>&lt;strong>实例粒度熔断&lt;/strong>：按照实例粒度进行熔断统计，主要用于解决单实例异常问题，如果触发了实例级别熔断，框架会自动重试。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>熔断器的思路很简单根据 RPC 成功或失败的情况，限制对下游的访问&lt;/strong>。通常熔断器分为三个时期：CLOSED、OPEN、HALFOPEN。当RPC 正常时，为 CLOSED；当 RPC 错误增多时，熔断器会被触发，进入 OPEN；OPEN 后经过一定的冷却时间，熔断器变为 HALFOPEN；HALFOPEN 时会对下游进行一些有策略的访问，然后根据结果决定是变为 CLOSED，还是 OPEN。总的来说三个状态的转换大致如下图：&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Conversion.png" alt="image">&lt;/p>
&lt;p>关于 Kitex 熔断器实现的更多细节和原理，可以查看官网基本特性 -&amp;gt; &lt;a href="https://www.cloudwego.io/zh/docs/kitex/tutorials/basic-feature/circuitbreaker/">熔断器&lt;/a>章节。&lt;/p>
&lt;h3 id="限流">&lt;strong>限流&lt;/strong>&lt;/h3>
&lt;p>如果说熔断是从客户端出发保护调用链，以防止系统雪崩，那么限流则是一种保护服务端的措施，防止上游某个 Client 流量突增导致 Server 过载。&lt;/p>
&lt;p>Kitex 支持限制最大连接数和最大 QPS。在初始化 Server 的时候，增加一个 Option：&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Server.png" alt="image">&lt;/p>
&lt;p>其中 &lt;code>MaxConnections&lt;/code> 表示最大连接数，MaxQPS` 表示最大 QPS，此外，Kitex 还提供了动态修改限流阈值的能力。&lt;/p>
&lt;p>Kitex 分别使用了 ConcurrencyLimiter 和 RateLimiter 对最大连接数和最大 QPS 进行限流，其中 ConcurrencyLimiter 采用了简单的计数器算法，RateLimiter 采用了“令牌桶算法”。&lt;/p>
&lt;p>限流状态的监控也是重要的一环，Kitex 定义了 &lt;code>LimitReporter&lt;/code> 接口，用于限流状态监控，例如当前连接数过多、QPS 过大等。如有需求，用户需要自行实现该接口，并通过 &lt;code>WithLimitReporter&lt;/code> 注入。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/LimitReporter.png" alt="image">&lt;/p>
&lt;h3 id="请求重试">&lt;strong>请求重试&lt;/strong>&lt;/h3>
&lt;p>Kitex 提供三类重试：超时重试、Backup Request，建连失败重试。其中建连失败是网络层面问题，由于请求未发出，框架会默认重试，下面重点介绍前两类重试的使用。需要注意的是，因为很多的业务请求不具有&lt;strong>幂等性&lt;/strong>，这两类重试不会作为默认策略，用户需要按需开启。&lt;/p>
&lt;ul>
&lt;li>&lt;strong>超时重试&lt;/strong>：错误重试的一种，即客户端收到超时错误的时候，发起重试请求。&lt;/li>
&lt;li>&lt;strong>Backup Request&lt;/strong>：客户端在一段时间内还没收到返回，发起重试请求，任一请求成功即算成功。Backup Request 的等待时间 &lt;code>RetryDelay&lt;/code> 建议配置为 TP99，一般远小于配置的超时时间 &lt;code>Timeout&lt;/code>。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Timeout.png" alt="image">&lt;/p>
&lt;p>服务中的长尾请求增加了服务的整体延迟，而长尾请求占比很低，如上图所示，一个真实服务的延迟分布，能明显看出长尾现象，最大延迟 60ms，而 99% 服务可以在 13ms 返回。当请求延迟达到 13ms 的时候就已经进入长尾请求，这个时候我们可以再发出一条请求，这条请求大概率会在 13ms 内返回，任意一次请求返回我们就认为请求成功，即通过增加适当的负载，大大减少了响应时间的波动。关于超时重试和 Backup Request 的优缺点以及适用场景，可见下表：&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Backup_Request.PNG" alt="image">&lt;/p>
&lt;h3 id="负载均衡">&lt;strong>负载均衡&lt;/strong>&lt;/h3>
&lt;p>Kitex 默认提供了两种负载均衡算法实现：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>WeightedRandom&lt;/strong>：这个算法使用的是基于权重的随机策略，也是 Kitex 的默认策略。它会依据实例的权重进行加权随机，并保证每个实例分配到的负载和自己的权重成比例。&lt;/li>
&lt;li>&lt;strong>ConsistentHash&lt;/strong>：一致性哈希主要适用于对上下文（如实例本地缓存）依赖程度高的场景，如希望同一个类型的请求打到同一台机器，则可使用该负载均衡方法。&lt;/li>
&lt;/ul>
&lt;p>ConsistentHash 在使用时，需要注意如下事项：&lt;/p>
&lt;ul>
&lt;li>下游节点发生变动时，一致性哈希结果可能会改变，某些 Key 可能会发生变化；&lt;/li>
&lt;li>如果下游节点非常多，第一次冷启动时 Build 时间可能会较长，如果 RPC 超时短的话可能会导致超时；&lt;/li>
&lt;li>如果第一次请求失败，并且 Replica 不为 0，那么会请求到 Replica 上；而第二次及以后仍然会请求第一个实例。&lt;/li>
&lt;/ul>
&lt;h3 id="可观测性">&lt;strong>可观测性&lt;/strong>&lt;/h3>
&lt;p>框架自身不提供监控打点实现，提供了 &lt;code>Tracer&lt;/code> 接口，用户可以根据需求实现该接口，并通过 &lt;code>WithTracer&lt;/code> Option 注入到框架中。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Tracer.png" alt="image">&lt;/p>
&lt;p>Kitex 的监控打点、Metrics 上报以及链路追踪，都可以通过上述接口进行扩展。&lt;/p>
&lt;p>目前 &lt;a href="https://github.com/kitex-contrib">kitex-contrib&lt;/a> 组织下提供了 &lt;a href="https://github.com/kitex-contrib/monitor-prometheus">Prometheus&lt;/a> 的监控扩展，&lt;a href="https://github.com/kitex-contrib/tracer-opentracing">OpenTracing&lt;/a> 的链路追踪扩展，以及 &lt;a href="https://github.com/kitex-contrib/obs-opentelemetry">OpenTelemetry&lt;/a> 可观测性全家桶（Metrics + Tracing + Logging）扩展实现，用户可以按需接入相应的扩展。&lt;/p>
&lt;h3 id="微服务框架与服务网格">&lt;strong>微服务框架与服务网格&lt;/strong>&lt;/h3>
&lt;p>&lt;strong>服务框架&lt;/strong>是传统微服务技术的核心所在。早期微服务技术中的服务注册、发现、调用、治理、观测都离不开服务框架。这也带来了一些问题，比如业务研发者需要感知并使用服务框架的服务治理能力，框架版本升级困难，框架越来越重难于维护等等。&lt;/p>
&lt;p>&lt;strong>服务网格（Service Mesh）&lt;/strong> 是将无侵入服务治理定义的更为深入的微服务架构方案，被称为第二代微服务架构。通过将微服务治理能力以独立组件（Sidecar）整合并下沉到基础设施，服务网格可以实现应用业务逻辑与服务治理逻辑完全分离，这也使支持&lt;strong>多语言&lt;/strong>、&lt;strong>热升级&lt;/strong>等高阶特性变得顺理成章。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Service_Mesh.png" alt="image">&lt;/p>
&lt;p>进入云原生时代，随着服务网格技术的逐步发展，我们也要用发展的眼光进行架构规划和设计，微服务框架和服务网格未来必定会是并存的，统一组成服务治理体系。在字节跳动，服务治理体系就是由服务框架和服务治理组成。以 Golang 服务为例，CloudWeGo 提供业务强相关、强侵入的服务治理，字节 Service Mesh 提供业务弱相关、弱侵入的服务治理，相互搭配，相互协商，既解决了业务开发所需的脚手架和开发模式，又让服务治理的接入更加容易。&lt;/p>
&lt;p>与此同时，在服务网格和服务框架同时使用的场景下，服务框架必须要支持灵活卸载治理能力，服务网格也需要保证功能的稳定性。在未来技术的演进方向上，服务框架也主要专注于编解码、通信效率、多协议支持等方面，而服务网格则可以深入更多无侵入的服务治理功能研发中。&lt;/p>
&lt;p>此外，在大规模场景下，针对服务治理新功能的研发需求决策，我们往往还需要考虑以下因素：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>性能:&lt;/strong> 大部分业务很在意，也是团队一直努力的重点；&lt;/li>
&lt;li>&lt;strong>普遍性&lt;/strong>:需要评估是不是所有业务都需要的能力；&lt;/li>
&lt;li>&lt;strong>简洁&lt;/strong>: 通俗说，我们不太希望引入太多的线上问题或者太复杂的使用说明文档；&lt;/li>
&lt;li>&lt;strong>ROI&lt;/strong>：功能迭代、产品升级需要考虑整体投资回报率。&lt;/li>
&lt;/ul>
&lt;h2 id="04-cloudwego-的开源之路">&lt;strong>04 CloudWeGo 的开源之路&lt;/strong>&lt;/h2>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Library.png" alt="image">&lt;/p>
&lt;p>字节内部版本的 Kitex 是依赖于开源版本的 Kitex，因此可以理解为 Kitex 内外同源，不存在两个 Kitex。&lt;/p>
&lt;h3 id="开源的原因">&lt;strong>开源的原因&lt;/strong>&lt;/h3>
&lt;p>回到开篇的问题，为什么要创造一个新的项目，并且开源 CloudWeGo 呢？&lt;/p>
&lt;p>首先，CloudWeGo 里面的项目都是在字节内部经过大规模落地实践验证的，开源后每个功能的迭代也都是第一时间在内部使用验证过的，是一个真正的企业级落地项目，开源用户和字节内部业务使用的是同一套服务框架；其次，CloudWeGo 提供的功能，尤其是协议支持和服务治理，都是能解决真实业务痛点的，每一行代码优化都能实实在在地提升用户服务的性能；最后，CloudWeGo 的研发也借鉴了一些知名开源项目的设计思路，同时也依赖一些开源项目的实现，我们把 CloudWeGo 开源出去也是为了回馈社区，给开源社区贡献一份力量。&lt;/p>
&lt;p>CloudWeGo 在设计之初，就同时考虑了正确性和可维护性，除了代码逻辑的正确性，高质量的代码、明晰的代码结构和优良的扩展性一直都是 CloudWeGo 追求的方向和实践的信条。&lt;/p>
&lt;p>CloudWeGo 服务于用户、需求驱动，为用户提供开箱即用的服务框架及相关中间件，希望可以服务于更多企业和独立开发者，避免用户重复创造。&lt;/p>
&lt;h3 id="开源的历程">&lt;strong>开源的历程&lt;/strong>&lt;/h3>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Course.PNG" alt="image">&lt;/p>
&lt;p>CloudWeGo 自 2021 年 9 月 8 日正式对外官宣，主要子项目 Kitex 先后发布 v0.1.0 和 v0.2.0，支持了许多新的功能，对性能、代码、文档也相继做了许多优化。截止到 2022 年 4 月，距离首次官宣 7 个月，仅 CloudWeGo-Kitex 就收获了 &lt;strong>4000&lt;/strong> 个 Star，累计近 &lt;strong>50&lt;/strong> 个 Contributors，达到了一个新的里程碑，这很有趣，并且十分振奋人心，不是吗？&lt;/p>
&lt;p>CloudWeGo 团队自开源之初就非常重视社区建设，“&lt;strong>Community Over Code&lt;/strong>” 也是 CloudWeGo 社区所遵循的文化和目标。&lt;/p>
&lt;p>从搭建用户群，建设官网和文档，积极维护项目 Issue，及时处理新的 PR，再到我们与贡献者的深入沟通和对他们的培养，每一个动作都体现我们的决心。为了推进社区建设规范化和标准化，CloudWeGo 团队先后创建了 Community 仓库用来定义社区成员晋升机制以及存档社区材料。&lt;/p>
&lt;p>为了践行公开透明和开源开放的开源文化，搭建开放的对话与交流平台，CloudWeGo 组织了社区双周例会，在例会上同步社区近期计划并积极听取社区成员的建议，与社区贡献者讨论相关技术方案实现。&lt;/p>
&lt;p>截止目前，通过社区 Maintainer 的培养、Contributor 的主动申请、社区管理委员会的投票审批，已经正式通过了 5 位 Committer 的加入申请，极大地壮大了 CloudWeGo 社区核心力量，他们为社区的发展作出了重大贡献。&lt;/p>
&lt;h3 id="后续的规划">&lt;strong>后续的规划&lt;/strong>&lt;/h3>
&lt;p>CloudWeGo 在 2021 年底收录进入 CNCF Landscape，丰富了 CNCF 在 RPC 领域的生态，给全球用户在做技术选型时提供了一套新的选择。&lt;/p>
&lt;p>尽管取得了一些小小的成绩，但是 CloudWeGo 仍旧还是一个年轻的项目，开源贵在持之以恒、长期建设，CloudWeGo 团队也会持续完善，继续向前。&lt;/p>
&lt;p>从社区建设方面来看，CloudWeGo 团队将继续提供更多新人友好的 Good-first-issue，坚持组织社区例会，定期举办开源技术沙龙，提供更易于理解的技术文档，另外也将继续欢迎更多新的开发者参与到社区建设中来。&lt;/p>
&lt;p>从开源规划来看，HTTP 框架 Hertz 开源在即，还有更多中间件小工具、扩展库也都在持续开源中。此外，CloudWeGo 主创团队还研发了一套 Rust RPC 框架，正在内部落地实践验证中，在不久的将来，也将对外开源。&lt;/p>
&lt;p>&lt;img src="/img/blog/Microservices_Open_CloudWeGo/Plan.png" alt="image">&lt;/p>
&lt;p>从功能研发计划来看，以 CloudWeGo-Kitex 为例，将继续以内外部用户需求为驱动力，持续开发新的功能并迭代完善已有的功能。其中，包括支持连接预热、自定义异常重试、对 Protobuf 支持的性能优化，支持 xDS 协议等。&lt;/p>
&lt;p>从开源生态来看，目前 CloudWeGo-Kitex 已经完成了诸多开源项目的对接，未来也将会按需支持更多开源生态。此外，CloudWeGo 也在和国内外主流公有云厂商进行合作对接，提供开箱即用、稳定可靠的微服务托管与治理产品的基座；CloudWeGo 也积极与国内外软件基金会开展合作和交流，探索新的合作模式。&lt;/p>
&lt;p>CloudWeGo 未来可期，我们期待更多用户使用我们的项目，也期待有更多开发者可以加入共建 CloudWeGo 社区，共同见证云原生时代一个初生但了不起的微服务中间件和开源项目。&lt;/p></description></item><item><title>Blog: 字节微服务框架的挑战和演进</title><link>/zh/blog/2022/05/19/%E5%AD%97%E8%8A%82%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E7%9A%84%E6%8C%91%E6%88%98%E5%92%8C%E6%BC%94%E8%BF%9B/</link><pubDate>Thu, 19 May 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/05/19/%E5%AD%97%E8%8A%82%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%A1%86%E6%9E%B6%E7%9A%84%E6%8C%91%E6%88%98%E5%92%8C%E6%BC%94%E8%BF%9B/</guid><description>
&lt;h1 id="字节微服务框架的挑战和演进">字节微服务框架的挑战和演进&lt;/h1>
&lt;p>2014 年以来，字节跳动内部业务的快速发展，推动了长连接推送服务，它们面临着高并发的业务需求问题，对性能和开发效率都有很高要求。当时的业务，大部分都是由 Python 开发，难以应对新出现的问题。项目负责人在一众现存的技术栈中选择了 Golang 这一门新兴的编程语言，快速解决了性能和开发效率的问题。随后，字节跳动内部开始逐渐推广使用 Golang 进行服务开发。&lt;/p>
&lt;p>2016 年， 第一代 Golang RPC 框架 Kite 正式发布。Kite 是一个基于 Apache Thrift 进行包装的 RPC 框架，它在 Facebook 开源的 Thrift 之上提供了结合字节跳动内部基础设施的治理功能，同时还提供了一套简单易用的生成工具。随着 Kite 的发展，业务开始大规模使用 Golang。然而，在业务发展的过程中，由于研发专注于实现业务需求，对于框架的可维护性考量不足，Kite 逐渐背上了一些技术包袱，越来越难以满足业务在高性能和新特性方面的需求。因此我们决定对 Kite 进行重新设计，于是出现了 Kitex。&lt;/p>
&lt;p>2020 年，Kitex 在内部发布了 v1.0.0，并且直接接入了 1,000+ 服务。由于 Kitex 的优秀性能和易用性，Kitex 在内部得到了大规模发展。直到 2021 年年中，字节跳动内部已有 2w+ 服务使用了 Kitex。因此，我们决定全面优化 Kitex，将其实践成果进行开源，反馈给开源社区。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/GolangRPC.png" alt="image">&lt;/p>
&lt;p align="center">
字节跳动 Golang RPC 框架的演进
&lt;/p>
&lt;h2 id="kite-的缺陷">Kite 的缺陷&lt;/h2>
&lt;p>Kite 作为字节跳动第一代 Golang RPC 框架，主要存在以下缺陷：&lt;/p>
&lt;ol>
&lt;li>Kite 为了快速支持业务发展需求，不可避免地耦合了部分中台业务的功能；&lt;/li>
&lt;li>Kite 对 Go modules 支持不友好（Go modules 在 2019 年才进入语言核心）；&lt;/li>
&lt;li>Kite 自身的代码拆分成多仓库，版本更新时推动业务升级困难；&lt;/li>
&lt;li>Kite 强耦合了早期版本的 Apache Thrift，协议和功能拓展困难；&lt;/li>
&lt;li>Kite 的生成代码逻辑与框架接口强耦合，成为了性能优化的天花板。&lt;/li>
&lt;/ol>
&lt;p>因此，业务的快速发展和需求场景的多样化，催生了新一代 Golang RPC 框架 Kitex。&lt;/p>
&lt;h2 id="kitex">Kitex&lt;/h2>
&lt;p>Kitex 的架构主要包括四个部分：Kitex Tool、Kitex Core、Kitex Byted、Second Party Pkg。&lt;/p>
&lt;ul>
&lt;li>Kitex Core 是一个携带了一套微服务治理功能的 RPC 框架，它是 Kitex 的核心部分。&lt;/li>
&lt;li>Kitex Byted 是一套结合了字节跳动内部基础设施的拓展集合。通过这一套拓展集合，Kitex 能够在内部支持业务的发展。&lt;/li>
&lt;li>Kitex Tool 是一个命令行工具，能够在命令行生成我们的代码以及服务的脚手架，可以提供非常便捷的开发体验。&lt;/li>
&lt;li>Second Party Pkg，例如 Netpoll， Netpoll-http2，是 Kitex 底层的网络库，这两个库也开源在 CloudWeGo 组织中。&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Architecture_design.png" alt="image">&lt;/p>
&lt;p align="center">
Kitex 的架构设计
&lt;/p>
&lt;p>总的来说， Kitex 主要有五个特点：面向开源、功能丰富、灵活可拓展、支持多协议、高性能。&lt;/p>
&lt;h2 id="面向开源">面向开源&lt;/h2>
&lt;p>由于之前已经体验过了 Kite 维护的各种问题，我们在立项之初就考虑到了未来可能会开源 Kitex。因此，我们设计的第一个宗旨就是不将 Kitex 和公司内部的基础设施进行强耦合或者硬编码绑定。Kitex Core 是一个非常简洁的框架，公司内部的所有基础设施都以拓展的方式注入到 Kitex Core 里。即使我们现在已经开源了，它也以这种形式存在。公司内部基础设施的更新换代，和 Kitex 自身的迭代是相互独立的，这对于业务来说是非常好的体验。同时，在 Kitex 的接口设计上，我们使用了 Golang 经典的 Option 模式，它是可变参数，通过 Option 能够提供各种各样的功能，这为我们的开发和业务的使用都带来了非常大的灵活性。&lt;/p>
&lt;h2 id="kitex-的功能特性">Kitex 的功能特性&lt;/h2>
&lt;h3 id="治理能力">治理能力&lt;/h3>
&lt;p>Kitex 内置了丰富的服务治理能力，例如超时熔断、重试、负载均衡、泛化调用、数据透传等功能。业务或者外部的用户使用 Kitex 都是可以开箱即用的。如果你有非常特殊的需求，你也可以通过我们的注入点去进行定制化操作，比如你可以自定义中间件去过滤或者拦截请求，定义跟踪器去注入日志、去注入服务发现等。在 Kitex 中，几乎一切跟策略相关的东西都是可以定制的。&lt;/p>
&lt;p>以服务发现为例，Kitex 的核心库里定义了一个 Resolver interface 。任何一个实现了这四个方法的类型都可以作为一个服务发现的组件，然后注入到 Kitex 来取代 Kitex 的服务发现功能。在使用时，客户端只需要创建一个 Resolver 的对象，然后通过 client.WithResolver 注入客户端，就可以使用自己开发的服务发现组件。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Resolver.png" alt="image">&lt;/p>
&lt;p>Kitex 的一个创新之处是使用 Suite 来打包自定义的功能，提供一键配置基础依赖的体验。&lt;/p>
&lt;p>它能在什么地方起作用呢？例如，一个外部企业想要启用或者接入 Kitex， 它不可能拥有字节跳动内部的所有基础设施。那么企业在使用的时候肯定需要定制化，他可能需要定义自己的注册中心、负载均衡、连接池等等。如果业务方要使用这些功能的话，就需要加入非常非常多的参数。而 Suite 可以通过一个简单的类一次性包装这些功能，由此，业务方使用时，仍然是以单一的参数的方式添加，十分方便。又例如，我现在开发一个叫 mysuite 的东西，我可能提供一个特殊的服务发现功能，提供了一个拦截的中间件，还有负载均衡功能等。业务方使用时，不需要感知很多东西去配置，只需要添加一个 Suite 就足够了，这点非常方便一些中台方或者第三方去做定制。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Suite.png" alt="image">&lt;/p>
&lt;p align="center">
示例
&lt;/p>
&lt;h3 id="多协议">多协议&lt;/h3>
&lt;p>Kitex 网络层基于高性能网络库 Netpoll 实现。在 Netpoll 上，我们构建了 Thrift 和 Netpoll-http2；在 Thrift 上，我们还做了一些特殊的定制，例如，支持 Thrift 的泛化调用，还有基于 Thrift 的连接多路复用。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Multi-protocol.png" alt="image">&lt;/p>
&lt;p align="center">
多协议
&lt;/p>
&lt;h3 id="代码生成工具">代码生成工具&lt;/h3>
&lt;p>和 Kitex 一同出现的，还有我们开发的一个简单易用的命令行工具。如果我们写了一个 IDL， 只需要提供一个 module 参数和一个服务名称，Kitex 就会为你生成服务代码脚手架。&lt;/p>
&lt;p>目前 Kitex 支持了 Protobuf 和 Thrift 这两种 IDL 的定义。命令行工具内置丰富的选项，可以进行项目代码定制；同时，它底层依赖 Protobuf 官方的编译器，和我们自研的 Thriftgo 的编译器，两者都支持自定义的生成代码插件。&lt;/p>
&lt;h2 id="kitex-的性能表现">Kitex 的性能表现&lt;/h2>
&lt;p>字节跳动内部 RPC 框架使用的协议主要都是基于 Thrift，所以我们在 Thrift 上深耕已久。结合自研的 netpoll 能力，它可以直接暴露底层连接的 buffer。在此基础上，我们设计出了 FastRead/FastWrite 编解码实现，测试发现它具有远超过 apache thrift 生成代码的性能。整体而言，Kitex 的性能相当不错，今年 1 月份的数据如下图所示，可以看到，Kitex 在使用 Thrift 作为 Payload 的情况下，性能优于官方 gRPC，吞吐接近 gRPC 的两倍；此外，在 Kitex 使用定制的 Protobuf 协议时，性能也优于 gRPC。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Kitex_gRPC.png" alt="image">&lt;/p>
&lt;p align="center">
Kitex/gRPC 性能对比（2022 年 1 月数据）
&lt;/p>
&lt;h2 id="kitex一个-demo">Kitex：一个 demo&lt;/h2>
&lt;p>下面简单演示一下 Kitex 是如何开发一个服务的。&lt;/p>
&lt;p>首先，定义 IDL。这里使用 Thrift 作为 IDL 的定义，编写一个名为 Demo 的 service。方法 Test 的参数是 String，它的返回也是 String。编写完这个 demo.thrift 文件之后，就可以使用 Kitex 在命令行生成指定的生成代码。如图所示，只需要传入 module name，service name 和目标 IDL 就行了。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/IDL.png" alt="image">&lt;/p>
&lt;p align="center">
定义 IDL
&lt;/p>
&lt;p>随后，我们需要填充业务逻辑。文件中除了第 12 行，全部代码都是 Kitex 命令行工具生成的。通常一个 RPC 方法需要返回一个 Response，例如这里需要返回一个字符串，那么我们给 Response 赋值即可。接下来需要通过 go mod tidy 把依赖拉下来，然后用 build.sh 构建，就可以启动服务了。Kitex 默认的接听端口是 8888。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Handler.png" alt="image">&lt;/p>
&lt;p align="center">
定义 Handler 方法
&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Compile_run.png" alt="image">&lt;/p>
&lt;p align="center">
编译、运行
&lt;/p>
&lt;p>对于刚刚启动的服务端，我们可以写一个简单的客户端去调用它。服务端写完之后，写客户端也是非常方便的。这里同样是 import 刚刚生成的生成代码，创建 Client、指定服务名字、构成相应的参数，填上“ Hello，word！” ，然后就可以调用了。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Client.png" alt="image">&lt;/p>
&lt;p align="center">
编写 Client
&lt;/p>
&lt;h1 id="kitex-在字节内部的落地">Kitex 在字节内部的落地&lt;/h1>
&lt;h2 id="与内部基础设施的集成">与内部基础设施的集成&lt;/h2>
&lt;p>谈到落地，第一步就是 Kitex 和字节跳动内部的基础设施进行结合。字节跳动内部的所有基础设施都是以依赖的方式注入到 Kitex 的。我们将日志、监控、tracing 都定义为 tracer，然后通过 WithTracer 这个 Option 将其注入到 Kitex 里；服务发现是 WithResolver；Service Mesh 则是 WithProxy 等。字节跳动内部的基础设施都是通过 Option 被注入到 Kitex 的，而且所有的 Option 都是通过前面说的 Suite 打包，简单地添加到业务的代码里完成。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Integration.png" alt="image">&lt;/p>
&lt;p align="center">
与内部基础设施的集成
&lt;/p>
&lt;h2 id="内部落地的经典案例合并部署">内部落地的经典案例：合并部署&lt;/h2>
&lt;p>这里介绍一个内部落地的经典案例：合并部署。其背景是，在开发微服务时，由于业务拆分和业务场景的多样化，微服务容易出现过微的情况。当服务数量越来越多，网络传输和序列化开销就会越来越大，变得不可忽视。因此，Kitex 框架需要考虑如何减小网络传输和序列化的开销。&lt;/p>
&lt;p>字节跳动基础架构经过一系列的探索和实践，最终推出了合并部署的机制。&lt;strong>它的思路&lt;/strong>是：将有强依赖关系的服务进行同机部署，减少它们之间的调用开销。理论上说起来比较简单，实际过程中需要非常多的组件进行配合。&lt;/p>
&lt;p>&lt;strong>Kitex 的做法&lt;/strong>是：首先，它会依赖一套中心化的部署调度和流量控制；其次，我们开发了一套基于共享内存的通信协议，它可以使得我们两个不同的服务在同一台机器部署时，不需要通过网络进行数据传输，直接通过共享内存，减少额外的数据拷贝。&lt;/p>
&lt;p>在服务合并部署的模式下，我们需要特殊的服务发现和连接池的实现、定制化的服务启动和监听逻辑。这些在 Kitex 框架里都是通过依赖注入的方式给添加进来的。Kitex 服务在启动过程中会感知到我们 PaaS 平台提供的指定的环境变量。当它察觉到自己需要按合并部署的方式启动之后，就会启动一个预先注入的特定 Suite，随后将相应的功能全都添加进来再启动，就可以执行我们的合并部署。&lt;/p>
&lt;p>那么，它的效果如何呢？在 2021 年的实践过程中，我们对抖音的某个服务约 30% 的流量进行了合并，服务端的 CPU 的消耗减少了 19%， TP99 延迟下降到 29%，效果相当显著。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Merge_deployment.png" alt="image">&lt;/p>
&lt;p align="center">
内部落地的经典案例：合并部署
&lt;/p>
&lt;h2 id="微服务框架推进的痛点">微服务框架推进的痛点&lt;/h2>
&lt;ul>
&lt;li>升级慢&lt;/li>
&lt;/ul>
&lt;p>大家可能好奇 Kitex 在字节跳动内部推广是不是很顺畅？其实并不是。作为一个相对而言比较新的框架， Kitex 和其它新生项目一样，在推广的过程中都会遇到同样的问题。特别是， Kitex 作为一个 RPC 框架，我们提供给用户的其实是一个代码的 SDK, 我们的更新是需要业务方的用户去感知、升级、部署上线，才能最终体现在他们的服务逻辑里，因此具有升级慢的问题。&lt;/p>
&lt;ul>
&lt;li>召回慢&lt;/li>
&lt;/ul>
&lt;p>同时，因为代码都是由研发人员编写，如果代码出现了 bug，我们就需要及时地去感知定位问题，通知负责人去更新版本。因此，会有召回慢的问题。&lt;/p>
&lt;ul>
&lt;li>问题排查困难&lt;/li>
&lt;/ul>
&lt;p>业务方的用户在写代码时，他们其实往往关注的是自己的业务逻辑，他们不会深入理解一个框架内部的实现。所以如果出现问题，他们往往会不知所措，需要依赖我们的业务同学才能进行相应的问题排查。所以会有问题排查困难的问题。&lt;/p>
&lt;p>针对&lt;strong>升级慢&lt;/strong>，我们有两个操作。一是，代码生成工具支持自动更新：当用户在使用时，我们会检查最新版本，然后直接将我们的版本更新到最新版本，这样可以及时把我们的框架新 feature、bug fix 直接推送到业务方；二是，用户群发版周知：我们有一个几千人的用户群，当有了新版本，我们会在用群里周知，可以最大范围的覆盖到我们的目标用户。&lt;/p>
&lt;p>针对&lt;strong>召回慢&lt;/strong>，我们有三个操作。一是，我们在线上建立完整的版本分布统计，监控所有服务上线部署的框架的版本；二是，我们会跟 PaaS 平台合作，在服务上线时进行卡点操作，检查它们使用的框架版本是不是有 bug，是否需要拦截；三是，针对有问题的版本，我们会及时封禁，及时推动用户更新。&lt;/p>
&lt;p>针对&lt;strong>问题排查困难&lt;/strong>，我们有两个操作。一是，我们积累了非常丰富的 Wiki 和问题排查手册，例如超时问题、 协议解析问题等。二是，如果遇到难以解决的问题，我们在线上服务默认开启了 Debug 端口，保证框架开发同学可以第一时间赶到现场去排查。&lt;/p>
&lt;h2 id="kitex-在字节内部的发展">Kitex 在字节内部的发展&lt;/h2>
&lt;p>数据显示，在 2020 年，v1.0 版本发布的初始阶段，用户的接受度比较低。直到 2020 年 6 月，线上接受 Kitex 的数量还不到 1000。随后进入快速发展的阶段，到 2021 年年初，累积接近 1w+ 的服务开始使用 Kitex。2021 年底，4w+服务使用 Kitex。&lt;/p>
&lt;p>&lt;img src="/img/blog/Evolution_Kitex_High-performance/Number_of_AccessServices.png" alt="image">&lt;/p>
&lt;h1 id="kitex-的开源实践">Kitex 的开源实践&lt;/h1>
&lt;p>开源工作主要包括代码、文档和社区运营三个层面。&lt;/p>
&lt;p>&lt;strong>代码层面&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>代码拆分、脱敏；&lt;/li>
&lt;li>内部仓库引用开源仓库，避免内外多副本同时维护；&lt;/li>
&lt;li>在开源过程中确保内部用户平滑切换、体验无损；&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>文档层面&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>重新梳理用户文档，覆盖方方面面；&lt;/li>
&lt;li>建立详尽的用例仓库(CloudWeGo/Kitex-examples)。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>社区运营&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>官网建设；&lt;/li>
&lt;li>组建用户群，进行答疑解惑；&lt;/li>
&lt;li>飞书机器人对接 Github 的 Issue 管理、PR 管理之类的业务，可以快速响应；&lt;/li>
&lt;li>对优秀贡献者进行奖励。&lt;/li>
&lt;/ul>
&lt;p>在以上努力下，CloudWeGo/Kitex 仓库目前收获了 4.1k+ stars；Kitex-Contrib 获得多个外部用户贡献的仓库；CloudWeGo 飞书用户群近 950 个用户……&lt;/p>
&lt;h1 id="未来展望">未来展望&lt;/h1>
&lt;p>首先，我们仍然会持续向开源社区反馈最新的技术进展。例如在 Thrift 协议上，虽然对 Thrift 的编解码已经做到非常极致的优化了，我们还在探索利用 JIT 手段来提供更多的性能提升；在 Protobuf 上，我们会补足短板，将在 Thrift 方面的优化经验迁移到 Protobuf 上，对 Protobuf 的生成代码和编解码进行优化；Kitex 后续也会进一步融入云原生社区，所以也在考虑支持 xDS 协议。其次，我们会去拓展更多的开源组件，去对接现存的云原生社区的各种常用的或者热门组件。最后，我们也会尝试去对接更多的公有云基础设施，使得用户在公有云上使用 Kitex 时能够拥有愉悦的体验。&lt;/p></description></item><item><title>Blog: Kitex v0.3.0 版本发布</title><link>/zh/blog/2022/04/29/kitex-v0.3.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/04/29/kitex-v0.3.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="feature">Feature&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/366">#366&lt;/a>, &lt;a href="https://github.com/cloudwego/kitex/pull/426">#426&lt;/a> ] 功能(client): 客户端支持预热操作&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/395">#395&lt;/a> ] 功能(mux): 连接多路复用支持优雅关闭&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/399">#399&lt;/a> ] 功能(protobuf): 定义 fastpb protocol API 并在编解码模块对应支持&lt;/li>
&lt;/ul>
&lt;h2 id="optimise">Optimise&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/402">#402&lt;/a> ] 优化(connpool): 导出 pkg/remote/connpool 里的 getCommonReporter&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/389">#389&lt;/a> ] 优化(rpcinfo)：填充由 defaultCodec 解码得到的 rpcinfo 中缺失的 Invocation().PackageName, Invocation().ServiceName and Config().TransportProtocol 字段&lt;/li>
&lt;/ul>
&lt;h2 id="bugfix">Bugfix&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/413">#413&lt;/a> ] 修复(mux): 在 NetpollMux transHandler 中设置 sendMsg的PayloadCodec，以修复泛化请求编码报错问题&lt;a href="https://github.com/cloudwego/kitex/issues/411">issue #411&lt;/a>&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/406">#406&lt;/a> ] 修复(grpc): 修复 http2 framer 的读写逻辑，例如避免对端无法及时收到 framer&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/398">#398&lt;/a> ] 修复(utils)：修复了 Dump() 接口无法 dump 出 ring 里所有数据的 bug&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/428">#428&lt;/a> ] 修复(trans)：当写入失败时，关闭连接以避免内存泄漏&lt;/li>
&lt;/ul>
&lt;h2 id="tool">Tool&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/340">#340&lt;/a> ] tool(protobuf): 重新设计并实现 Protobuf 生成代码，不使用反射完成编解码，当前仅支持 proto3&lt;/li>
&lt;/ul>
&lt;h2 id="chore">Chore&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/396">#396&lt;/a> ] chore: 用 bytedance/gopkg 里的 xxhash3 替换掉 cespare/xxhash&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/400">#400&lt;/a> ] chore: 升级 workflow 的 go 版本到 1.18&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/407">#407&lt;/a> ] chore: 单独增加文件对 grpc 源码使用做声明&lt;/li>
&lt;/ul>
&lt;h2 id="test">Test&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/401">#401&lt;/a> ] test: 补充 kitex/server 的单测&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/393">#393&lt;/a> ] test: 补充 pkg/remote/bound package 单测&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/403">#403&lt;/a> ] test: 补充 netpollmux package 单测&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/401">#401&lt;/a> ] test: 补充 klog package 单测&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/392">#392&lt;/a> ] test: 补充 utils package 单测&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/373">#373&lt;/a>, &lt;a href="https://github.com/cloudwego/kitex/pull/432">#432&lt;/a>, &lt;a href="https://github.com/cloudwego/kitex/pull/434">#434&lt;/a> ] test: 补充 gRPC transport 部分的单测，单测覆盖率提升到 76%&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/424">#424&lt;/a> ] test: 补充 transmeta 实现 handler 的单元测试&lt;/li>
&lt;/ul>
&lt;h2 id="dependency-change">Dependency Change&lt;/h2>
&lt;ul>
&lt;li>github.com/cloudwego/netpoll: v0.2.0 -&amp;gt; v0.2.2&lt;/li>
&lt;li>github.com/bytedance/gopkg: 20210910103821-e4efae9c17c3 -&amp;gt; 20220413063733-65bf48ffb3a7&lt;/li>
&lt;/ul></description></item><item><title>Blog: Netpoll v0.2.2 版本发布</title><link>/zh/blog/2022/04/28/netpoll-v0.2.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Thu, 28 Apr 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/04/28/netpoll-v0.2.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="improvement">Improvement&lt;/h2>
&lt;ul>
&lt;li>Fix: Loops 缩容不再全部重置&lt;/li>
&lt;li>Chore: mcache bsr 计算使用 math/bits.Len 代替，以提升性能。&lt;/li>
&lt;li>Feat: 修复 LinkBuffer Close 时没有回收 caches 的问题（不是内存泄漏）&lt;/li>
&lt;/ul>
&lt;h2 id="fix">Fix&lt;/h2>
&lt;ul>
&lt;li>Fix: 修复短链接 send&amp;amp;close 场景无法触发 OnRequest 回调的问题&lt;/li>
&lt;li>Fix: 修复 zcReader 读到 io.EOF 后丢失部分数据的问题&lt;/li>
&lt;li>Fix: 修复 flush 没有检查连接关闭的问题&lt;/li>
&lt;/ul>
&lt;h2 id="doc">Doc&lt;/h2>
&lt;ul>
&lt;li>Doc: 更新了用户文档&lt;/li>
&lt;li>Doc: 增加了 Reader.Slice 的定义描述&lt;/li>
&lt;li>Doc: 修复了 examples 中的死链&lt;/li>
&lt;/ul>
&lt;h2 id="revert">Revert&lt;/h2>
&lt;ul>
&lt;li>Revert: 重置了 loops 初始化数量&lt;/li>
&lt;/ul></description></item><item><title>Blog: CloudWeGo 助 NextArch 基金会推动标准化建设</title><link>/zh/blog/2022/04/01/cloudwego-%E5%8A%A9-nextarch-%E5%9F%BA%E9%87%91%E4%BC%9A%E6%8E%A8%E5%8A%A8%E6%A0%87%E5%87%86%E5%8C%96%E5%BB%BA%E8%AE%BE/</link><pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/04/01/cloudwego-%E5%8A%A9-nextarch-%E5%9F%BA%E9%87%91%E4%BC%9A%E6%8E%A8%E5%8A%A8%E6%A0%87%E5%87%86%E5%8C%96%E5%BB%BA%E8%AE%BE/</guid><description>
&lt;blockquote>
&lt;p>导语：2022 年 3 月，NextArch 基金会正式成立微服务技术小组，致力于推动微服务技术和开源生态的持续发展，根据各个企业在微服务生产实践中遇到的问题，针对不同行业和应用场景输出标准化解决方案，并且联合 PolarisMesh、TARS、go-zero、GoFrame、&lt;strong>&lt;a href="https://github.com/cloudwego">CloudWeGo&lt;/a>&lt;/strong> 和 Spring Cloud Tencent 等开源社区提供开箱即用的实现，降低终端用户的使用门槛。来自腾讯、字节跳动、七牛云、快手、BIGO、好未来和蓝色光标等多家企业的技术专家已经加入技术小组，欢迎更多企业和开源社区加入。&lt;/p>
&lt;/blockquote>
&lt;p>2021 年 11 月，Linux 基金会正式成立 NextArch 基金会，共计 40 余家企业或单位联合参与了该基金会的筹建工作，并作为首批共建和支持单位加入，目前已增至 53 家企业。NextArch 基金会致力于在异构基础设施、多元化技术栈和混合云场景下的构建下一代技术架构，始终秉承一个开放中立的治理模式，发展适合企业数字化转型的开源生态。&lt;/p>
&lt;p>微服务是下一代架构的关键部分，越来越多企业采用微服务架构。市场调研表明，随着企业数字化转型持续深入，2023 年微服务云市场的规模达到 18.8 亿美元，从 2018 到 2023 年的复合年增长率达到 22.4%。众所周知，微服务相比于传统架构具有诸多优势，但是，我们在微服务实施的各个环节中都可能面临问题。&lt;/p>
&lt;p>为了降低微服务架构的落地成本，来自腾讯、快手、字节跳动、好未来、七牛云和蓝色光标等多家企业的技术专家在 NextArch 基金会成立微服务技术小组，共同探讨各自企业在微服务领域中遇到的问题，分享大家在生产过程中的实践经验，并且面向不同的应用场景和终端用户，联合相关开源社区输出标准化的解决方案。&lt;/p>
&lt;p>&lt;img src="/img/blog/CloudWeGo_helps_NextArch/community.png" alt="image">&lt;/p>
&lt;p>在采用微服务架构之前，我们需要思考为什么采用微服务架构，并不是所有的开发团队和发展阶段都适合采用微服务架构。通常，采用微服务架构可以解决以下问题：首先，开发团队具有一定的规模，所有成员共同开发一个单体应用的内耗太高，如果采用微服务架构，每个服务可以由单个或者少数成员独立负责。第二，业务系统的功能模块很多，耦合在一起会增加测试和部署的成本，任何一个模块故障也会导致整个系统故障。第三，功能模块之间的负载无法隔离，容易互相影响，没有办法针对热点模块的计算层或者存储层进行扩容。&lt;/p>
&lt;p>如果我们采用微服务架构，单个服务是⾮常简单的，但是，分布式服务之间的功能调用远⽐单体应用内部更加复杂。在单体应用中，⼀个函数可以调⽤其他任何一个公共函数。在微服务架构中，一个函数只可以调⽤同⼀个微服务的函数。如何实现分布式服务之间的通信是微服务架构的首要问题，构建高性能、高可用的远程调用能力并不容易。值得庆幸的是，已经有 grpc、thrift、tars、go-zero、GoFrame、&lt;a href="https://github.com/cloudwego/kitex">cloudwego/kitex&lt;/a> 和 spring cloud 等大量开源的分布式服务开发框架，这些框架可以帮助终端用户快速地构建微服务。不幸的是，仅仅把服务开发出来并且跑通是不够的，保障大规模服务的稳定运营还需要考虑诸多问题，例如：在分布式架构中如何处理基础设施以及应用层的各种异常、如何实现大规模服务的无损发布和流量调度，如何定位和分析复杂调用链路中出现的问题等。对于中大型企业来说，还存在异构的开发技术栈和运行时环境，存在跨地域和混合云的架构要求，如何在更加复杂的应用场景中解决上述问题，面临更多的挑战。&lt;/p>
&lt;p>目前，这个方向还没有开箱即用的解决方案，终端用户必须在不同的基础设施和适当的工具之间做出抉择，才能解决各种问题。近日，NextArch 微服务技术小组向基金会提交了首个提案，根据各自企业在分布式或者微服务生产实践中的经验和痛点，面向多语言、多框架和异构基础设施，针对不同行业和应用场景输出微服务落地的标准化方案，并且依托相关开源社区提供推荐实现，方便终端用户落地。我们也期待更多企业和开源社区加入 NextArch 基金会，共同探讨分布式或者微服务治理的标准化方案。&lt;/p>
&lt;p>&lt;img src="/img/blog/CloudWeGo_helps_NextArch/framework.png" alt="image">&lt;/p>
&lt;h3 id="部分-nextarch-microservice-sig-成员引文">部分 NextArch Microservice SIG 成员引文：&lt;/h3>
&lt;p>&lt;strong>PolarisMesh 单家骏&lt;/strong>&lt;/p>
&lt;p>腾讯云专家工程师，具备 10 年以上中间件研发经验。北极星开源社区（PolarisMesh）联合发起人，负责开源项目的技术规划、代码开发和社区运营等工作。&lt;/p>
&lt;p>自分布式架构发展至今，微服务成为了复杂业务系统的首选模式，在企业得到了充分的生产落地，然而各个微服务框架及工具链，对于微服务治理体系的理解存在差异性，使得业务系统在实现微服务治理上存在较大的成本，同时也不利于微服务技术的沉淀及长期发展。北极星是腾讯自研和开源的微服务治理框架，覆盖了腾讯内部 90% 以上的业务，解决了业务系统因多语言、多框架以及业务差异性所带来的服务治理不一致的问题，在腾讯内部完成了服务发现和治理的标准化。我们期望通过加入 NextArch 基金会这样一个中立组织，可以讨论业界微服务治理的相关实践及解决方案，沉淀出标准化的服务治理体系，促进微服务生态的进一步发展，也期望北极星开源社区可以推动并承载微服务治理标准体系的落地。&lt;/p>
&lt;p>&lt;strong>go-zero 万俊峰&lt;/strong>&lt;/p>
&lt;p>万俊峰，七牛云技术副总裁，go-zero 开源社区/go-zero 作者。负责 go-zero 框架的规划、代码编写、代码 review、工具链规划、社区建设、开源推广&lt;/p>
&lt;p>微服务在发展了这么多年之后，已经呈现出百花齐放的状态，各种微服务框架和治理能力在很多公司都得到了充分的落地，并带来了巨大的业务价值。但当前的现状也没有形成足够的技术共识和规范，我们需要进一步提炼和抽象微服务的能力，并加以标准化。这样可以更好的沉淀经验，并将各语言的微服务框架提供规划化对接，从而推动微服务技术的进一步发展。同时也期望在 SIG 组织能够更多的讨论微服务落地的各种最佳实践，也期望能够通过 go-zero 开源社区帮助推动共识的微服务治理标准落地。&lt;/p>
&lt;p>&lt;strong>GoFrame 郭强&lt;/strong>&lt;/p>
&lt;p>腾讯高级工程师，GoFrame 开源框架项目发起人及主要贡献者，负责 GoFrame 框架发展规划、社区建设维护、核心代码开发。GoFrame 是一款模块化、高性能、企业级的 Go 基础开发框架。&lt;/p>
&lt;p>微服务是一种架构设计思想，目的是为了有效解决业务复杂度提高带来的项目架构问题。微服务需要解决的不仅是技术问题，也是项目协作问题。在&amp;quot;微服务化&amp;quot;过后，项目架构将引入更多的痛点：职责边界界定、服务高效通信、分布事务处理、微服务化治理、服务版本管理、项目迭代协作等等。微服务思想发展至今，这些痛点的解决方案已比较成熟，并且大同小异。NextArch 微服务 SIG 需要做的是在这些方案之上分析共性之处，形成统一化和规范化的解决方案。以帮助企业更快速地实现微服务化，同时，也需要提供一些最佳实践，帮助企业提高在服务化后的项目管理手段。80% 的解决方案抽象，20% 的最佳实践沉淀。&lt;/p>
&lt;p>&lt;strong>CloudWeGo 罗广明&lt;/strong>&lt;/p>
&lt;p>字节跳动微服务架构师，CloudWeGo 开源负责人。CloudWeGo 是一套由字节跳动开源的、可快速构建企业级云原生架构的中间件集合，专注于解决微服务通信与治理的难题，具备高性能、可扩展、高可靠的特点。&lt;/p>
&lt;p>微服务技术发展至今，业界涌现出一大批微服务开发框架、技术和最佳实践。这个多样化是不可避免的，没有一个微服务开发框架能够统一所有的语言，但是微服务架构里面所涉及的服务治理体系，却可以做到统一和规范化。NextArch 微服务 SIG 正是在这样的背景下诞生了，旨在提供统一服务治理体系，解决共性问题，将促进微服务框架和技术的进一步演进和发展。&lt;/p></description></item><item><title>Blog: 一文了解字节跳动微服务中间件 CloudWeGo</title><link>/zh/blog/2022/03/28/%E4%B8%80%E6%96%87%E4%BA%86%E8%A7%A3%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6-cloudwego/</link><pubDate>Mon, 28 Mar 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/03/28/%E4%B8%80%E6%96%87%E4%BA%86%E8%A7%A3%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6-cloudwego/</guid><description>
&lt;p>云原生时代，各行各业的基础架构都在经历微服务架构转型，研发效率和稳定性是所有互联网公司需要考虑的问题。开发者想要搭建微服务，离不开配套的微服务治理，如治理平台、监控、链路跟踪、注册/发现、配置中心、服务网格等。随着 Golang 逐渐成为云原生时代的主要编程语言，基于 Golang 的微服务中间件在开源社区有着较强的诉求。&lt;/p>
&lt;p>字节跳动也同样面临这些问题。2014 年，字节跳动引入 Golang 解决长连接推送业务面临的高并发问题，两年后，内部技术团队基于 Golang 推出了一个名为 Kite 的框架，同时对开源项目 Gin 做了一层很薄的封装，推出了 Ginex。字节跳动基础架构/服务框架团队负责人成国柱在 QCon 2021 的分享中表示，这两个原始框架的推出，极大推动了 Golang 在公司内部的应用。&lt;/p>
&lt;p>但是由于关联技术迭代和业务诉求增加，深度耦合的 Kite 和 Thrift ，很难从网络模型或编解码层面改造优化，继续支持新特性势必会造成代码臃肿、迭代受阻问题。2019 年下半年，字节跳动技术团队开始重新设计 Golang RPC 框架，同时为了在网络通信上有更好的性能并能支持连接多路复用、感知连接状态，自研了网络库 Netpoll。&lt;/p>
&lt;p>字节跳动重构 Kite 为 Kitex ，围绕性能和可扩展性设计，并在次年 10 月完成发布，投入到内部应用中。据悉，截至 2021 年 9 月，线上有 3w+ 微服务使用 Kitex，大部分服务迁移新框架后可以收获 CPU 和延迟上的收益。&lt;/p>
&lt;p>“在 Kitex 得到内部广泛使用后，我们决定围绕微服务逐步把我们的实践开源出去，并且对外保持统一。”字节跳动 CloudWeGo 技术专家谈道，“但微服务相关的项目较多，每个项目单独开源对外部用户并不友好，因此我们以 CloudWeGo 作为项目名，逐步将内部整个微服务体系开源，内外统一使用开源库，各项目以开源库为主进行迭代。”&lt;/p>
&lt;p>2021 年 9 月 8 日，字节跳动宣布正式开源 CloudWeGo。&lt;/p>
&lt;h2 id="中间件工具箱cloudwego">&lt;strong>中间件“工具箱”CloudWeGo&lt;/strong>&lt;/h2>
&lt;p>CloudWeGo 是一套字节跳动内部微服务中间件集合，具备高性能、强扩展性和稳定性的特点，专注于解决微服务通信与治理的难题，满足不同业务在不同场景的诉求。此外，CloudWeGo 也重视与云原生生态的集成，支持对接 K8s 注册中心、Prometheus 监控以及 OpenTracing 链路追踪等。&lt;/p>
&lt;p>目前，CloudWeGo 第一批开源了四个项目：&lt;a href="https://github.com/cloudwego/kitex">Kitex&lt;/a>、&lt;a href="https://github.com/cloudwego/netpoll">Netpoll&lt;/a>、&lt;a href="https://github.com/cloudwego/thriftgo">Thriftgo&lt;/a> 和 &lt;a href="https://github.com/cloudwego/netpoll-http2">netpoll-http2&lt;/a>，以 RPC 框架 Kitex 和网络库 Netpoll 为主。Kitex 内置了部分治理策略以及丰富的扩展接口，便于融入微服务体系中；Netpoll 主要面向对高性能有诉求的场景。&lt;/p>
&lt;p>CloudWeGo 的每一个组件都可以单独使用。“很多人担心 Kitex 是一个很重的框架，其实 Kitex 没有耦合任何其他组件包括 Netpoll，Kitex 内置的一些治理能力，用户也可以选择性集成。Netpoll 作为一个网络库，其他 RPC 框架、HTTP 框架都可以单独接入使用。Thriftgo 是 Thrift IDL 解析和代码生成器，也是独立的工具，并且提供插件机制，用户可定制生成代码。”字节跳动 CloudWeGo 技术专家表示，“我们会继续开源其他内部项目，如 HTTP 框架 Hertz、基于共享内存的 IPC 通信库 ShmIPC 等，提供更多场景的微服务需求支持。”&lt;/p>
&lt;h2 id="cloudwego-的优势和局限">&lt;strong>CloudWeGo 的优势和局限&lt;/strong>&lt;/h2>
&lt;p>微服务中间件和业务紧密联系，是整个业务架构的基础，在进行技术选型时必须慎重。业内公认的选型标准关键在于两方面：&lt;/p>
&lt;ul>
&lt;li>能解决实际业务问题和上生产抗流量，且易用性高、可治理、成熟稳定&lt;/li>
&lt;li>技术是开源的，且开源项目的 star 数、项目活跃度（Issue&amp;amp;PR）、文档更新频率、发版周期稳定可靠&lt;/li>
&lt;/ul>
&lt;p>CloudWeGo 的优势在于，已经在字节跳动经过大规模生产流量验证，有可以参考的稳定性和可靠性实际案例。“CloudWeGo 的特点之一是高性能，但实际上在开发之初它经常遇到性能瓶颈，于是内部专门进行了网络库、Thrift 序列化的专项优化，优化的过程会比较漫长，一个瓶颈点要花很长时间反复测试调整实现，我们也发过两篇文章&lt;a href="http://www.cloudwego.io/zh/blog/2021/09/23/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-go-rpc-%E6%A1%86%E6%9E%B6-kitex-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/">《字节跳动 Go RPC 框架 Kitex 性能优化实践》&lt;/a>和&lt;a href="http://www.cloudwego.io/zh/blog/2021/10/09/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%9C%A8-go-%E7%BD%91%E7%BB%9C%E5%BA%93%E4%B8%8A%E7%9A%84%E5%AE%9E%E8%B7%B5/">《字节跳动在 Go 网络库上的实践》&lt;/a>分享了优化实践。”字节跳动 CloudWeGo 技术专家表示。&lt;/p>
&lt;p>据悉，与同类型项目相比，CloudWeGo 开发团队不仅考虑了高性能、强扩展性，还考虑到了易用性。“以 Kitex 为例，目前从治理功能的多样性上不及一些开源框架，从性能、扩展性、使用体验多维度综合来看，Kitex 具有一定的优势。Kitex 支持多协议，由于内部以 Thrift 为主，Kitex 对 Thrift 支持也做了性能优化，如果使用 Thrift，Kitex 将是最佳的选择。”字节跳动 CloudWeGo 技术专家告诉 InfoQ。&lt;/p>
&lt;p>此外，为了遵守长期投入承诺，内外维护一套代码、统一迭代，字节跳动已经将与内部生态没有耦合的项目直接迁移到 CloudWeGo 开源库，并将内部依赖调整为开源库。而对于需要集成治理能力融入微服务体系的 Kitex，开源团队则对内外部代码做了拆分，把 Kitex 的核心代码迁移到开源库，内部库封装一层壳保证用户无感知升级，而集成内部治理特性的模块则作为 Kitex 的扩展保留在内部库。未来，字节跳动也会持续把已经在内部经过稳定性验证的新特性，迁移到开源库。&lt;/p>
&lt;p>在字节跳动内部，为了便于 Kitex 融入内部的治理体系，Kitex 面向内部提供了 Byted Suite 扩展，集成内部的注册中心、配置中心、监控等，内部 ServiceMesh 已经得到了大规模落地，Kitex 会根据服务的信息判断是否是 ServiceMesh 模式，若是，Kitex 则会卸载治理组件，治理能力下沉至 Mesh 中。为了提高与 ServiceMesh 通信的性能，Kitex 单独扩展 TransHandler 模块集成内部实现的 ShmIPC，与 ServiceMesh 通信走 ShmIPC ，后续 Kitex 对 ShmIPC 的扩展以及 ShmIPC 库也会开源出来。&lt;/p>
&lt;p>不过 CloudWeGo 依然有自己的局限性。字节跳动 CloudWeGo 技术专家告诉 InfoQ：CloudWeGo 功能的丰富度和多样性还不够，还需要进一步完善，字节跳动技术团队会收集外部用户的需求，评估排期支持，期待更多的开发者加入。目前 Kitex Server 性能优势明显，但 Client 相比 Server 性能表现不佳，后续会重点对 Client 进行优化。此外，基于不同的语言框架，默认场景必须能兼容互通而非性能最佳。“刚开源时得到大家的关注，看到一些压测对比显示 Kitex 性能表现一般，主要是压测场景未对齐，后续我们也会考虑面向开源尽量提供性能较优的策略。”&lt;/p>
&lt;h2 id="开源不是为了完成-kpi-">&lt;strong>“开源”不是为了“完成 KPI ”&lt;/strong>&lt;/h2>
&lt;p>目前，CloudWeGo 在社区中也比较有活力。据悉，在未被正式宣布开源前，一个月内 Kitex 收获了 1.2k stars，Netpoll 收获了 700+ stars。9 月 8 日，字节跳动正式宣布开源 CloudWeGo 后，截至 10 月初，项目整体 star 数已经超过 4800，且已被收录进 CNCF landscape。&lt;/p>
&lt;p>&lt;img src="/img/blog/article_to_learn_about_CloudWeGo/image.png" alt="image">&lt;/p>
&lt;p>字节跳动 CloudWeGo 技术专家表示：“我们收到了来自社区的大量反馈，如很多用户对 Protobuf 的诉求较为强烈，我们已经针对这个问题，计划开展 Kitex 对 Protobuf 支持的性能优化。欢迎大家向 CloudWeGo 提交 issue 和 PR，共建 CloudWeGo。我们也为企业和组织使用 Kitex 和 Netpoll 设置了专项支持，希望 CloudWeGo 将来能真正成为通用的、可落地的微服务通信与治理开源方案。”&lt;/p>
&lt;p>关于开源，字节跳动 CloudWeGo 技术专家的观点旗帜鲜明：“完成 KPI 不是这个项目开源的目的。健康的开源模式注重开放共享，共同成长和长期主义。CloudWeGo 认同个体参与、社区价值以及开源共同体带来的归属感。”&lt;/p>
&lt;p>“字节跳动作为开源项目的受益者、参与者，也希望成为开源项目的推动者、主导者，将内部优秀的最佳实践反馈给开源社区，与社区共同建设、丰富基础架构领域开源生态，为广大开发者和企业在技术选型时提供更多更优的选择。”字节跳动 CloudWeGo 技术专家谈道，“我们拥抱开源的文化，倾听社区的反馈，积极响应用户的需求，并且提供友好的中英文文档和快速开发 guideline，为社区开发者快速深入了解 CloudWeGo 以及参与贡献提供便利与支持。”&lt;/p>
&lt;p>&lt;strong>项目地址：&lt;/strong>&lt;a href="https://github.com/cloudwego">https://github.com/cloudwego&lt;/a>&lt;/p>
&lt;p>&lt;strong>受访嘉宾:&lt;/strong> 字节跳动 CloudWeGo 技术专家罗广明、杨芮、马子昂&lt;/p>
&lt;p>&lt;strong>原文链接:&lt;/strong> &lt;a href="https://www.infoq.cn/article/9ixlu4kjapg3ufhymm3j">https://www.infoq.cn/article/9ixlu4kjapg3ufhymm3j&lt;/a>&lt;/p></description></item><item><title>Blog: Kitex v0.2.1 版本发布</title><link>/zh/blog/2022/03/24/kitex-v0.2.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Thu, 24 Mar 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/03/24/kitex-v0.2.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="bugfix">Bugfix&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/383">#383&lt;/a> ] 修复(generic)：在泛化调用的时候检查 IDL 是否有循环依赖。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/359">#359&lt;/a> ] 修复(tool)：修复 protobuf CombineService 缺失 streaming 引用的问题。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/363">#363&lt;/a> ] 修复(client)：修复 oneway 请求的 sequence ID 没有被编码的问题以及降低 oneway 调用的丢包率。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/367">#367&lt;/a> ] 修复(generic/tool)：修复 CombineServices 可能存在多次加载同一个 service 问题。&lt;/li>
&lt;/ul>
&lt;h2 id="optimise">Optimise&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/362">#362&lt;/a> ] 优化(diagnosis)：lbcaches 是全局的，无需为每个 client 注册 ProbeFunc 用于诊断查询。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/374">#374&lt;/a> ] 优化(rpcinfo)：RPCInfo.To().Tag() 优先使用服务发现的 instance tag 而不是 remoteinfo tag。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/355">#355&lt;/a> ] 优化(连接池)：修改默认的连接池最小空闲等待时间为 2s。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/354">#354&lt;/a> ] 优化(hook)：为 &lt;code>onServerStart&lt;/code>和 &lt;code>onShutdown&lt;/code>添加资源锁，当做一些如&lt;code>RegisterStartHook&lt;/code>和 &lt;code>server.Run&lt;/code>中的 &lt;code>range&lt;/code>之类的读写操作时请求对应的资源锁。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/331">#331&lt;/a> ] 优化(discovery)：增加「实例不存在」错误定义。&lt;/li>
&lt;/ul>
&lt;h2 id="refactor">Refactor&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/352">#352&lt;/a> ] 重构(event)：删除额外的原子操作并用普通赋值操作替换。&lt;/li>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/343">#343&lt;/a> ] 重构(loadbalancer)：将 buildWeightedVirtualNodes 函数合入 buildVirtualNodes 函数中，成为一个函数。&lt;/li>
&lt;/ul>
&lt;h2 id="chore">Chore&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/376">#376&lt;/a> ] 升级依赖 choleraehyq/pid 以兼容Go 1.18。&lt;/li>
&lt;/ul>
&lt;h2 id="docs">Docs&lt;/h2>
&lt;ul>
&lt;li>[&lt;a href="https://github.com/cloudwego/kitex/pull/364">#364&lt;/a> ] 更新 README 到新博客的链接。&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.2.0 版本发布</title><link>/zh/blog/2022/02/24/kitex-v0.2.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Thu, 24 Feb 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/02/24/kitex-v0.2.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="feature">Feature&lt;/h2>
&lt;ul>
&lt;li>Feat(grpc): gRPC 相关配置支持通过 options 来设置，并且为了兼容旧版本默认窗口大小调整为 64K&lt;/li>
&lt;li>Feat(kerror): 为 basicError 添加新的 error 封装 func WithCauseAndExtraMsg&lt;/li>
&lt;li>Feat(rpcinfo): 添加 FreezeRPCInfo 以支持异步 context 使用&lt;/li>
&lt;li>Feat(codec): 默认编解码器支持限定包体积大小&lt;/li>
&lt;/ul>
&lt;h2 id="bugfix">Bugfix&lt;/h2>
&lt;ul>
&lt;li>Fix(remotecli): 修复重置的连接可能被复用的问题&lt;/li>
&lt;li>Fix(generic): 修复泛化调用的客户端不能使用继承的 service 的方法的问题&lt;/li>
&lt;li>Fix(generic): 修复泛化调用 client 侧判断 Oneway 不准确的问题&lt;/li>
&lt;/ul>
&lt;h2 id="optimise">Optimise&lt;/h2>
&lt;ul>
&lt;li>Optimize(retry): 提高异常重试的重试成功率&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>如果超时的请求先于重试的请求返回，可能会导致重试请求也失败；同时也可以避免超时请求不必要的解码处理。&lt;/p>
&lt;/blockquote>
&lt;h2 id="chore">Chore&lt;/h2>
&lt;ul>
&lt;li>Chore: 升级 netpoll 的版本至 v0.2.0&lt;/li>
&lt;li>Chore: 添加第三方库的license&lt;/li>
&lt;/ul></description></item><item><title>Blog: Netpoll v0.2.0 版本发布</title><link>/zh/blog/2022/02/22/netpoll-v0.2.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Tue, 22 Feb 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/02/22/netpoll-v0.2.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="improvement">Improvement&lt;/h2>
&lt;ul>
&lt;li>Feat: 添加 OnConnect 回调&lt;/li>
&lt;li>Feat: 新增 Until API&lt;/li>
&lt;li>Feat: 支持不带 timeout 的 dial&lt;/li>
&lt;/ul>
&lt;h2 id="fix">Fix&lt;/h2>
&lt;ul>
&lt;li>Fix: 修复当只设置了 onConnect 回调时，不会触发 close callback 的 bug&lt;/li>
&lt;li>Fix: 添加最大节点限制，避免异常情况下的 OOM 问题&lt;/li>
&lt;li>Fix: 修复 reset operator 时，没有 reset OnWrite 的问题&lt;/li>
&lt;li>Fix: 修复连接关闭时，写 panic 的问题&lt;/li>
&lt;li>Fix: 修复单测失败问题&lt;/li>
&lt;/ul>
&lt;h2 id="chore">Chore&lt;/h2>
&lt;ul>
&lt;li>docs: 更新 readme&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.1.4 版本发布</title><link>/zh/blog/2022/01/18/kitex-v0.1.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Tue, 18 Jan 2022 00:00:00 +0000</pubDate><guid>/zh/blog/2022/01/18/kitex-v0.1.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="功能优化">功能优化&lt;/h2>
&lt;ul>
&lt;li>在 rpctimeout 的 middleware 的输出日志中过滤掉超时日志&lt;/li>
&lt;li>调整默认日志级别为 Info&lt;/li>
&lt;li>给 sentAt 变量加锁，避免单测出现 DATA RACE，实际上不会有并发问题&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复&lt;/h2>
&lt;ul>
&lt;li>修复客户端编码失败时连接会泄漏的问题&lt;/li>
&lt;li>修复 middleware builder 中设置 TimeoutAdjust 不生效的问题&lt;/li>
&lt;/ul>
&lt;h2 id="工具">工具&lt;/h2>
&lt;ul>
&lt;li>修复 protobuf 的 handler 参数名&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>kitex 会给每个 stream server 生成一个名为 &amp;ldquo;{{.ServiceName}}&lt;em>{{.Name}}Server&amp;rdquo; 的 stream 类型，
但是在 handler.go 中使用的是 &amp;ldquo;{{.ServiceName}}&lt;/em>{{.RawName}}Server&lt;/p>
&lt;/blockquote>
&lt;h2 id="chore">Chore&lt;/h2>
&lt;ul>
&lt;li>删除不必要的类型转换&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.1.3 版本发布</title><link>/zh/blog/2021/12/30/kitex-v0.1.3-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Thu, 30 Dec 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/12/30/kitex-v0.1.3-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="功能优化">功能优化&lt;/h2>
&lt;ul>
&lt;li>JSON 泛化调用场景，向服务端传递 Base 信息，从而服务端可获取 Caller 等信息&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复&lt;/h2>
&lt;ul>
&lt;li>修复 streaming 的 metric 上报（server侧）丢失 method 信息的问题&lt;/li>
&lt;li>修复 JSON 和 HTTP 泛化中 base64 和 binary 的不兼容改动&lt;/li>
&lt;li>修复 gRPC 流控相关的问题，该问题会导致 client 侧出现持续超时&lt;/li>
&lt;/ul>
&lt;h2 id="ci">CI&lt;/h2>
&lt;ul>
&lt;li>增加场景测试&lt;/li>
&lt;/ul>
&lt;h2 id="chore">Chore&lt;/h2>
&lt;ul>
&lt;li>更新了 &lt;a href="https://github.com/cloudwego/kitex/blob/develop/ROADMAP.md">ROADMAP&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.1.2 版本发布</title><link>/zh/blog/2021/12/22/kitex-v0.1.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Wed, 22 Dec 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/12/22/kitex-v0.1.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="hotfix">Hotfix&lt;/h2>
&lt;ul>
&lt;li>修复 v0.1.0 gRPC 请求优化引入的部分问题&lt;/li>
&lt;li>修复 IDL 中未定义 package 时，gRPC 的方法信息错误问题&lt;/li>
&lt;/ul>
&lt;h2 id="依赖更新">依赖更新&lt;/h2>
&lt;ul>
&lt;li>更新 netpoll-http2 依赖，解决 streaming 场景下大包（&amp;gt;4K）请求报错的问题&lt;/li>
&lt;/ul>
&lt;h2 id="杂项">杂项&lt;/h2>
&lt;ul>
&lt;li>使用 GitHub 的 PR 模板，强制开发者提交 PR 时填写相关描述&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.1.0 版本发布</title><link>/zh/blog/2021/12/13/kitex-v0.1.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/12/13/kitex-v0.1.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="功能">功能&lt;/h2>
&lt;h3 id="泛化调用">泛化调用&lt;/h3>
&lt;ul>
&lt;li>IDL 解析支持多 Service&lt;/li>
&lt;li>暴露 SetSeqID 方法便于二进制泛化场景 server 侧使用&lt;/li>
&lt;li>泛化 client 支持关闭，规避内存泄漏问题&lt;/li>
&lt;/ul>
&lt;h3 id="日志">日志&lt;/h3>
&lt;ul>
&lt;li>修改日志风格，使用 &amp;ldquo;key=value&amp;rdquo; 列出信息&lt;/li>
&lt;li>使用 klog 作为全局的日志输出工具&lt;/li>
&lt;li>使用全局的 default logger&lt;/li>
&lt;li>日志打印更多 context 信息，例如 logId，方便问题排查&lt;/li>
&lt;li>go func 传入服务信息用于 recover panic 后输出关键信息方便问题排查&lt;/li>
&lt;/ul>
&lt;h3 id="option">Option&lt;/h3>
&lt;ul>
&lt;li>增加 NewThriftCodecDisableFastMode 方法，来关闭 FastWrite 和 FastRead&lt;/li>
&lt;li>Kitex server 支持端口复用&lt;/li>
&lt;li>默认 RPC 超时设置为 0（在后续 PR 中，revert 了该变更）&lt;/li>
&lt;/ul>
&lt;h3 id="proxy">Proxy&lt;/h3>
&lt;ul>
&lt;li>Proxy 增加 ContextHandler 接口用于传递初始化ctx给 mwbuilder&lt;/li>
&lt;li>注册 lbcache 的 Dump 给 diagnosis，用于问题诊断&lt;/li>
&lt;li>将 PRCConfig 传递给 proxy.Config&lt;/li>
&lt;/ul>
&lt;h2 id="优化">优化&lt;/h2>
&lt;ul>
&lt;li>减少了对象的堆分配&lt;/li>
&lt;li>优化多路复用性能&lt;/li>
&lt;li>优化 grpc 编解码性能，通过 Release 时释放(Close) LinkBuffer&lt;/li>
&lt;li>在计算 backup request 的消耗(cost)时，区分 ErrRPCFinish&lt;/li>
&lt;li>多路复用分片队列逻辑移动至 netpoll/mux，并重命名分片字典&lt;/li>
&lt;li>优化Fast api中容器类型的长度编码逻辑&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复&lt;/h2>
&lt;ul>
&lt;li>修复 server 端 WithErrorHandler 配置不生效问题&lt;/li>
&lt;li>调整 lbcache 中的 Balancer 初始化逻辑&lt;/li>
&lt;li>修复 TraceCtl 可能为 nil 的问题(仅影响单测)&lt;/li>
&lt;li>设置默认的 rpc timeout, 并支持设置 WithRPCTimeout(0) 来关闭超时中间件&lt;/li>
&lt;li>修复 default logger 使用错误的 call depth&lt;/li>
&lt;li>重命名 BackwardProxy 为 ReverseProxy&lt;/li>
&lt;li>修复 grpc 场景下的 panic&lt;/li>
&lt;li>修复 grpc 场景下的潜在风险（keepalive 超时导致 panic）&lt;/li>
&lt;li>修复 void 方法中的异常缺失&lt;/li>
&lt;li>修复实例变更时 dump 信息不正确问题。&lt;/li>
&lt;/ul>
&lt;h2 id="文档">文档&lt;/h2>
&lt;ul>
&lt;li>修复失效的中文链接&lt;/li>
&lt;li>将全部 doc 移至官网 cloudwego.io&lt;/li>
&lt;/ul>
&lt;h2 id="netpoll-api-change">Netpoll API Change:&lt;/h2>
&lt;ul>
&lt;li>适应 netpoll.Writer.Append 的 API 改动，返回值从 2个 变为 1个&lt;/li>
&lt;/ul>
&lt;h2 id="依赖变化">依赖变化&lt;/h2>
&lt;ul>
&lt;li>github.com/cloudwego/netpoll: v0.0.4 -&amp;gt; v0.1.2&lt;/li>
&lt;/ul></description></item><item><title>Blog: Netpoll v0.1.2 版本发布</title><link>/zh/blog/2021/12/13/netpoll-v0.1.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 13 Dec 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/12/13/netpoll-v0.1.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="bug-修复">Bug 修复:&lt;/h2>
&lt;ul>
&lt;li>LinkBuffer 增加了空值校验&lt;/li>
&lt;/ul></description></item><item><title>Blog: Netpoll v0.1.1 版本发布</title><link>/zh/blog/2021/12/09/netpoll-v0.1.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Thu, 09 Dec 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/12/09/netpoll-v0.1.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="优化">优化:&lt;/h2>
&lt;ul>
&lt;li>优化了多路复用下，分片队列的性能&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复:&lt;/h2>
&lt;ul>
&lt;li>修复了 book 方法在多路复用下的 bug&lt;/li>
&lt;/ul>
&lt;h2 id="文档">文档&lt;/h2>
&lt;ul>
&lt;li>修正了一些大小写和语法问题，并更新了链接&lt;/li>
&lt;/ul></description></item><item><title>Blog: Netpoll v0.1.0 版本发布</title><link>/zh/blog/2021/12/01/netpoll-v0.1.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/12/01/netpoll-v0.1.0-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="功能">功能:&lt;/h2>
&lt;ul>
&lt;li>增加了分片队列，用于支持连接多路复用&lt;/li>
&lt;li>优化方案：尽可能的维护单节点 LinkBuffer 来减少 copy&lt;/li>
&lt;li>优化方案：修复了 waitReadSize 的 bug，并优化了 input trigger 效率&lt;/li>
&lt;li>优化方案：减少了 waitRead 和 inputAck 冲突时产生的超时错误&lt;/li>
&lt;li>逻辑简化：简化了连接状态机&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复:&lt;/h2>
&lt;ul>
&lt;li>修复了 eventLoop 提前 GC 的 bug&lt;/li>
&lt;/ul>
&lt;h2 id="文档">文档&lt;/h2>
&lt;ul>
&lt;li>更新 README，将 Performance 部分移动至 netpoll-benchmark 项目&lt;/li>
&lt;li>更新了 reference，添加了官网信息，移除了 change log&lt;/li>
&lt;/ul>
&lt;h2 id="重大变更">重大变更&lt;/h2>
&lt;ul>
&lt;li>WriteBuffer 返回值由 (n int, err error) 改为 (err error)&lt;/li>
&lt;/ul></description></item><item><title>Blog: RPC 框架 Kitex 实践入门：性能测试指南</title><link>/zh/blog/2021/11/24/rpc-%E6%A1%86%E6%9E%B6-kitex-%E5%AE%9E%E8%B7%B5%E5%85%A5%E9%97%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E5%8D%97/</link><pubDate>Wed, 24 Nov 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/11/24/rpc-%E6%A1%86%E6%9E%B6-kitex-%E5%AE%9E%E8%B7%B5%E5%85%A5%E9%97%A8%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E6%8C%87%E5%8D%97/</guid><description>
&lt;blockquote>
&lt;p>2021 年 9 月 8 日，字节跳动宣布正式开源 CloudWeGo。CloudWeGo 是一套字节跳动内部微服务中间件集合，具备高性能、强扩展性和稳定性的特点，专注于解决微服务通信与治理的难题，满足不同业务在不同场景的诉求。CloudWeGo 第一批开源了四个项目：Kitex、Netpoll、Thriftgo 和 netpoll-http2，以 RPC 框架 Kitex 和网络库 Netpoll 为主。&lt;/p>
&lt;/blockquote>
&lt;p>日前，字节跳动服务框架团队正式开源 &lt;a href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMjE0MQ==&amp;amp;mid=2247490160&amp;amp;idx=1&amp;amp;sn=9fce5fec2e6520d4637bcf5a3d483edd&amp;amp;chksm=e9d0d192dea758845c85d1e9a73532a08da09afffdfc003a33168d858efb43ae79855594844e&amp;amp;scene=21#wechat_redirect">CloudWeGo&lt;/a> ，在抖音、今日头条均有深度应用的 Golang 微服务 RPC 框架 Kitex 也包含在其中。&lt;/p>
&lt;p>本文旨在分享开发者在压测 Kitex 时需要了解的场景和技术问题。这些建议有助于用户更好地结合真实 RPC 场景对 Kitex 进行调优，使之更贴合业务需要、发挥最佳性能。用户也可以参考官方提供的压测项目 &lt;a href="https://github.com/cloudwego/kitex-benchmark">kitex-benchmark&lt;/a> 了解更多细节。&lt;/p>
&lt;h2 id="微服务场景的特点">微服务场景的特点&lt;/h2>
&lt;p>Kitex 诞生于字节跳动大规模微服务架构实践，面向的场景自然是微服务场景，因此下面会先介绍微服务的特点，方便开发者深入理解 Kitex 在其中的设计思考。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>RPC 通信模型&lt;/p>
&lt;p>微服务间的通信通常以 PingPong 模型为主，所以除了常规的吞吐性能指标外，每次 RPC 的平均时延也是开发者需要考虑的点。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>复杂的调用链路&lt;/p>
&lt;p>一次 RPC 调用往往需要多个微服务协作完成，而下游服务又会有其自身依赖，所以整个调用链路会是一个复杂的网状结构。&lt;/p>
&lt;p>在这种复杂调用关系中，某个中间节点出现的延迟波动可能会传导到整个链路上，导致整体超时。当链路上的节点足够多时，即便每个节点的波动概率很低，最终汇聚到链路上的超时概率也会被放大。所以单一服务的延迟波动 —— 即 P99 延迟指标，也是一个会对线上服务产生重大影响的关键指标。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>包体积大小&lt;/p>
&lt;p>虽然一个服务通信包的大小取决于实际业务场景，但在字节跳动的内部统计中，我们发现线上请求大多以小包（&amp;lt;2KB）为主，所以在兼顾大包场景的同时，也重点优化了小包场景下的性能。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="针对微服务场景进行压测">针对微服务场景进行压测&lt;/h2>
&lt;h3 id="确定压测对象">确定压测对象&lt;/h3>
&lt;p>衡量一个 RPC 框架的性能需要从两个视角分别去思考：Client 视角与 Server 视角。在大规模的业务架构中，上游 Client 不见得使用的也是下游的框架，而开发者调用的下游服务也同样如此，如果再考虑到 Service Mesh 的情况就更复杂了。&lt;/p>
&lt;p>一些压测项目通常会把 Client 和 Server 进程混部进行压测，然后得出&lt;strong>整个框架&lt;/strong>的性能数据，这其实和线上实际运行情况很可能是不符的。&lt;/p>
&lt;p>如果要压测 Server，应该给 Client 尽可能多的资源，把 Server 压到极限，反之亦然。如果 Client 和 Server 都只给了 4 核 CPU 进行压测，会导致开发者无法判断最终得出来的性能数据是哪个视角下的，更无法给线上服务做实际的参考。&lt;/p>
&lt;h3 id="对齐连接模型">对齐连接模型&lt;/h3>
&lt;p>常规 RPC 的连接模型主要有三种：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>短连接&lt;/strong>：每次请求都创建新连接，得到返回后立即关闭连接&lt;/li>
&lt;li>&lt;strong>长连接池&lt;/strong>：单个连接同时只能处理一次完整请求与返回&lt;/li>
&lt;li>&lt;strong>连接多路复用&lt;/strong>：单个连接可以同时异步处理多个请求与返回&lt;/li>
&lt;/ul>
&lt;p>每类连接模型没有绝对好坏，取决于实际使用场景。连接多路复用虽然一般来说性能相对最好，但应用上必须依赖协议能够支持包序列号，且一些老框架服务可能也并不支持多路复用的方式调用。&lt;/p>
&lt;p>Kitex 最早为保证最大程度的兼容性，在 Client 端默认使用了短连接，而其他主流开源框架默认使用连接多路复用，这导致一些用户在使用默认配置压测时，出现了比较大的性能数据偏差。&lt;/p>
&lt;p>后来为了契合开源用户的常规使用场景，Kitex 在 v0.0.2 中也加入了&lt;a href="https://github.com/cloudwego/kitex/pull/40/files">默认使用长连接&lt;/a>的设置。&lt;/p>
&lt;h3 id="对齐序列化方式">对齐序列化方式&lt;/h3>
&lt;p>对于 RPC 框架来说，不考虑服务治理的话，计算开销主要都集中在序列化与反序列化中。&lt;/p>
&lt;p>Kitex 对于 Protobuf 的序列化使用的是官方的 &lt;a href="https://github.com/golang/protobuf">Protobuf&lt;/a> 库，对于 Thrift 的序列化，则专门进行了性能优化，这方面的内容在&lt;a href="https://www.cloudwego.io/zh/blog/2021/09/23/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-go-rpc-%E6%A1%86%E6%9E%B6-kitex-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/#thrift-%E5%BA%8F%E5%88%97%E5%8C%96%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%E4%BC%98%E5%8C%96">官网博客&lt;/a>中有介绍。&lt;/p>
&lt;p>当前开源框架大多优先支持 Protobuf，而部分框架内置使用的 Protobuf 其实是做了许多性能优化的 &lt;a href="https://github.com/gogo/protobuf">gogo/protobuf&lt;/a> 版本，但由于 gogo/protobuf 当前有&lt;a href="https://github.com/gogo/protobuf/issues/691">失去维护的风险&lt;/a>，所以出于可维护性角度考虑，我们依然决定只使用官方的 Protobuf 库，当然后续我们也会计划对 Protobuf 进行优化。&lt;/p>
&lt;h3 id="使用独占-cpu">使用独占 CPU&lt;/h3>
&lt;p>虽然线上应用通常是多个进程共享 CPU，但在压测场景下，Client 与 Server 进程都处于极端繁忙的状况，如果同时还共享 CPU 会导致大量上下文切换，从而使得数据缺乏可参考性，且容易产生前后很大波动。&lt;/p>
&lt;p>所以我们建议是将 Client 与 Server 进程隔离在不同 CPU 或者不同独占机器上进行。如果还想要进一步避免其他进程产生影响，可以再加上 nice -n -20 命令调高压测进程的调度优先级。&lt;/p>
&lt;p>另外如果条件允许，相比云平台虚拟机，使用真实物理机会使得测试结果更加严谨与具备可复现性。&lt;/p>
&lt;h2 id="性能数据参考">性能数据参考&lt;/h2>
&lt;p>在满足上述要求的前提下，我们对多个框架使用 Protobuf 进行了压测对比，压测代码在 kitex-benchmark 仓库。在充分压满 Server 的目标下，Kitex 在连接池模式下的 P99 Latency 在所有框架中最低。而在多路复用模式下，Kitex 在各指标上也都具有更加明显的优势。&lt;/p>
&lt;p>&lt;strong>配置：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>Client 16 CPUs，Server 4 CPUs&lt;/li>
&lt;li>1KB 请求大小，Echo 场景&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>参考数据：&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>KITEX：连接池模式（默认模式）&lt;/li>
&lt;li>KITEX-MUX：多路复用模式&lt;/li>
&lt;li>其他框架均使用多路复用模式&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="/img/blog/kitex_performance_testing/qps.png" alt="image">
&lt;img src="/img/blog/kitex_performance_testing/tp99.png" alt="image">&lt;/p>
&lt;h2 id="结语">结语&lt;/h2>
&lt;p>在当前主流的 Golang 开源 RPC 框架中，每个框架其实在设计目标上都各有侧重：有些框架侧重于通用性，有些侧重于类似 Redis 这种轻业务逻辑的场景，有些侧重于吞吐性能，而有些则更侧重 P99 时延。&lt;/p>
&lt;p>字节跳动的业务在日常迭代中，常常会出现因某个 feature 导致一个指标上升，另一个指标下降的情况，因此 Kitex 在设计之初就更倾向于解决大规模微服务场景下各种问题。&lt;/p>
&lt;p>Kitex 发布后，我们接到了大量来自用户的自测数据，感谢社区对我们的关注和支持，也欢迎广大开发者基于本文提供的测试指南，针对自己的实际场景选择合适的工具。更多问题，请在 GitHub 上提 Issue 交流。&lt;/p>
&lt;h2 id="相关链接">相关链接&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>CloudWeGo 官网: &lt;a href="https://www.cloudwego.io">https://www.cloudwego.io&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Kitex: &lt;a href="https://github.com/cloudwego/kitex">https://github.com/cloudwego/kitex&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Netpoll: &lt;a href="https://github.com/cloudwego/netpoll">https://github.com/cloudwego/netpoll&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>kitex-benchmark: &lt;a href="https://github.com/cloudwego/kitex-benchmark">https://github.com/cloudwego/kitex-benchmark&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>netpoll-benchmark: &lt;a href="https://github.com/cloudwego/netpoll-benchmark">https://github.com/cloudwego/netpoll-benchmark&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>官方 Protobuf 库：https://github.com/golang/protobuf&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Thriftgo：https://github.com/cloudwego/thriftgo&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.0.8 版本发布</title><link>/zh/blog/2021/11/05/kitex-v0.0.8-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Fri, 05 Nov 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/11/05/kitex-v0.0.8-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="优化">优化&lt;/h2>
&lt;ul>
&lt;li>使用分片 ring 减少连接池的锁开销。&lt;/li>
&lt;li>装填 TTHeader 中的上游服务信息到 rpcinfo 中，用于在 decode 出错时输出来源信息。&lt;/li>
&lt;li>Unlink uds 调整至 CreateListener 中。&lt;/li>
&lt;li>event.go 和 ring_single.go 中的 Mutex 改为 RWMutex。&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复&lt;/h2>
&lt;ul>
&lt;li>修复 netpollmux shard index 溢出的问题。&lt;/li>
&lt;li>移除 &lt;code>WithCircuitBreaker&lt;/code> option 里对参数的反射，避免 data-race。&lt;/li>
&lt;li>在重试场景下， 修复 rpc finish 错误导致的小概率失败的问题，并且加上了熔断 sample 的校验。&lt;/li>
&lt;li>修复 endpoint_test.go 中的一处单测错误。&lt;/li>
&lt;li>修改 conn_wrapper.go 中 longconn 变量命名为 conn.。&lt;/li>
&lt;/ul>
&lt;h2 id="生成工具">生成工具&lt;/h2>
&lt;ul>
&lt;li>代码生成工具支持透传thrift-go插件参数。&lt;/li>
&lt;/ul>
&lt;h2 id="文档">文档&lt;/h2>
&lt;ul>
&lt;li>将 README 中的性能结果改为引用 kitex-benchmark 仓库的数据。&lt;/li>
&lt;/ul>
&lt;h2 id="依赖变化">依赖变化&lt;/h2>
&lt;ul>
&lt;li>github.com/tidwall/gjson: v1.8.0 -&amp;gt; v1.9.3&lt;/li>
&lt;/ul></description></item><item><title>Blog: 字节跳动在 Go 网络库上的实践</title><link>/zh/blog/2021/10/09/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%9C%A8-go-%E7%BD%91%E7%BB%9C%E5%BA%93%E4%B8%8A%E7%9A%84%E5%AE%9E%E8%B7%B5/</link><pubDate>Sat, 09 Oct 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/10/09/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%9C%A8-go-%E7%BD%91%E7%BB%9C%E5%BA%93%E4%B8%8A%E7%9A%84%E5%AE%9E%E8%B7%B5/</guid><description>
&lt;blockquote>
&lt;p>本文选自“字节跳动基础架构实践”系列文章。&lt;/p>
&lt;p>“字节跳动基础架构实践”系列文章是由字节跳动基础架构部门各技术团队及专家倾力打造的技术干货内容，和大家分享团队在基础架构发展和演进过程中的实践经验与教训，与各位技术同学一起交流成长。&lt;/p>
&lt;p>RPC 框架作为研发体系中重要的一环，承载了几乎所有的服务流量。本文将简单介绍字节跳动自研网络库 netpoll 的设计及实践；以及我们实际遇到的问题和解决思路，希望能为大家提供一些参考。&lt;/p>
&lt;/blockquote>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>RPC 框架作为研发体系中重要的一环，承载了几乎所有的服务流量。随着公司内 Go 语言使用越来越广，业务对框架的要求越来越高，而 Go 原生 net 网络库却无法提供足够的性能和控制力，如无法感知连接状态、连接数量多导致利用率低、无法控制协程数量等。为了能够获取对于网络层的完全控制权，同时先于业务做一些探索并最终赋能业务，框架组推出了全新的基于 epoll 的自研网络库 —— netpoll，并基于其之上开发了字节内新一代 Golang 框架 Kitex。&lt;/p>
&lt;p>由于 epoll 原理已有较多文章描述，本文将仅简单介绍 netpoll 的设计；随后，我们会尝试梳理一下我们基于 netpoll 所做的一些实践；最后，我们将分享一个我们遇到的问题，以及我们解决的思路。同时，欢迎对于 Go 语言以及框架感兴趣的同学加入我们！&lt;/p>
&lt;h2 id="新型网络库设计">新型网络库设计&lt;/h2>
&lt;h3 id="reactor---事件监听和调度核心">Reactor - 事件监听和调度核心&lt;/h3>
&lt;p>netpoll 核心是 Reactor 事件监听调度器，主要功能为使用 epoll 监听连接的文件描述符（fd），通过回调机制触发连接上的 读、写、关闭 三种事件。&lt;br>
&lt;br/>
&lt;img src="/img/blog/bytedance_gonet_practice_img/reactor.png" alt="image">&lt;/p>
&lt;h3 id="server---主从-reactor-实现">Server - 主从 Reactor 实现&lt;/h3>
&lt;p>netpoll 将 Reactor 以 1:N 的形式组合成主从模式。&lt;/p>
&lt;ol>
&lt;li>MainReactor 主要管理 Listener，负责监听端口，建立新连接；&lt;/li>
&lt;li>SubReactor 负责管理 Connection，监听分配到的所有连接，并将所有触发的事件提交到协程池里进行处理。&lt;/li>
&lt;li>netpoll 在 I/O Task 中引入了主动的内存管理，向上层提供 NoCopy 的调用接口，由此支持 NoCopy RPC。&lt;/li>
&lt;li>使用协程池集中处理 I/O Task，减少 goroutine 数量和调度开销。&lt;br>
&lt;br/>
&lt;img src="/img/blog/bytedance_gonet_practice_img/server_reactor.png" alt="image">&lt;/li>
&lt;/ol>
&lt;h3 id="client---共享-reactor-能力">Client - 共享 Reactor 能力&lt;/h3>
&lt;p>client 端和 server 端共享 SubReactor，netpoll 同样实现了 dialer，提供创建连接的能力。client 端使用上和 net.Conn 相似，netpoll 提供了 write -&amp;gt; wait read callback 的底层支持。&lt;br>
&lt;br/>
&lt;img src="/img/blog/bytedance_gonet_practice_img/client_reactor.png" alt="image">&lt;/p>
&lt;h2 id="nocopy-buffer">Nocopy Buffer&lt;/h2>
&lt;h3 id="为什么需要-nocopy-buffer-">为什么需要 Nocopy Buffer ?&lt;/h3>
&lt;p>在上述提及的 Reactor 和 I/O Task 设计中，epoll 的触发方式会影响 I/O 和 buffer 的设计，大体来说分为两种方式：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>采用水平触发(LT)&lt;/strong>，则需要同步的在事件触发后主动完成 I/O，并向上层代码直接提供 buffer。&lt;/li>
&lt;li>&lt;strong>采用边沿触发(ET)&lt;/strong>，可选择只管理事件通知(如 go net 设计)，由上层代码完成 I/O 并管理 buffer。&lt;/li>
&lt;/ul>
&lt;p>两种方式各有优缺，netpoll 采用前者策略，水平触发时效性更好，容错率高，主动 I/O 可以集中内存使用和管理，提供 nocopy 操作并减少 GC。事实上一些热门开源网络库也是采用方式一的设计，如 easygo、evio、gnet 等。&lt;/p>
&lt;p>但使用 LT 也带来另一个问题，即底层主动 I/O 和上层代码并发操作 buffer，引入额外的并发开销。比如：I/O 读数据写 buffer 和上层代码读 buffer 存在并发读写，反之亦然。为了保证数据正确性，同时不引入锁竞争，现有的开源网络库通常采取 同步处理 buffer(easygo, evio) 或者将 buffer 再 copy 一份提供给上层代码(gnet) 等方式，均不适合业务处理或存在 copy 开销。&lt;/p>
&lt;p>另一方面，常见的 bytes、bufio、ringbuffer 等 buffer 库，均存在 growth 需要 copy 原数组数据，以及只能扩容无法缩容，占用大量内存等问题。因此我们希望引入一种新的 Buffer 形式，一举解决上述两方面的问题。&lt;/p>
&lt;h3 id="nocopy-buffer-设计和优势">Nocopy Buffer 设计和优势&lt;/h3>
&lt;p>Nocopy Buffer 基于链表数组实现，如下图所示，我们将 []byte 数组抽象为 block，并以链表拼接的形式将 block 组合为 Nocopy Buffer，同时引入了引用计数、nocopy API 和对象池。&lt;br>
&lt;br/>
&lt;img src="/img/blog/bytedance_gonet_practice_img/buffer.png" alt="image">&lt;br>
&lt;br/>
Nocopy Buffer 相比常见的 bytes、bufio、ringbuffer 等有以下优势：&lt;/p>
&lt;ol>
&lt;li>读写并行无锁，支持 nocopy 地流式读写
&lt;ul>
&lt;li>读写分别操作头尾指针，相互不干扰。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>高效扩缩容
&lt;ul>
&lt;li>扩容阶段，直接在尾指针后添加新的 block 即可，无需 copy 原数组。&lt;/li>
&lt;li>缩容阶段，头指针会直接释放使用完毕的 block 节点，完成缩容。每个 block 都有独立的引用计数，当释放的 block 不再有引用时，主动回收 block 节点。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>灵活切片和拼接 buffer (链表特性)
&lt;ul>
&lt;li>支持任意读取分段(nocopy)，上层代码可以 nocopy 地并行处理数据流分段，无需关心生命周期，通过引用计数 GC。&lt;/li>
&lt;li>支持任意拼接(nocopy)，写 buffer 支持通过 block 拼接到尾指针后的形式，无需 copy，保证数据只写一次。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Nocopy Buffer 池化，减少 GC
&lt;ul>
&lt;li>将每个 []byte 数组视为 block 节点，构建对象池维护空闲 block，由此复用 block，减少内存占用和 GC。基于该 Nocopy Buffer，我们实现了 Nocopy Thrift，使得编解码过程内存零分配零拷贝。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="连接多路复用">连接多路复用&lt;/h2>
&lt;p>RPC 调用通常采用短连接或者长连接池的形式，一次调用绑定一个连接，那么当上下游规模很大的情况下，网络中存在的连接数以 MxN 的速度扩张，带来巨大的调度压力和计算开销，给服务治理造成困难。因此，我们希望引入一种 &amp;ldquo;在单一长连接上并行处理调用&amp;rdquo; 的形式，来减少网络中的连接数，这种方案即称为 &amp;ldquo;连接多路复用&amp;rdquo;。&lt;/p>
&lt;p>当前业界也存在一些开源的连接多路复用方案，掣肘于代码层面的束缚，这些方案均需要 copy buffer 来实现数据分包和合并，导致实际性能并不理想。而上述 Nocopy Buffer 基于其灵活切片和拼接的特性，很好的支持了 nocopy 的数据分包和合并，使得实现高性能连接多路复用方案成为可能。&lt;/p>
&lt;p>基于 netpoll 的连接多路复用设计如下图所示，我们将 Nocopy Buffer(及其分片) 抽象为虚拟连接，使得上层代码保持同 net.Conn 相同的调用体验。与此同时，在底层代码上通过协议分包将真实连接上的数据灵活的分配到虚拟连接上；或通过协议编码合并发送虚拟连接数据。&lt;br>
&lt;br/>
&lt;img src="/img/blog/bytedance_gonet_practice_img/client_server.png" alt="image"> &lt;br>
&lt;br/>
连接多路复用方案包含以下核心要素：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>虚拟连接&lt;/p>
&lt;ul>
&lt;li>实质上是 Nocopy Buffer，目的是替换真正的连接，规避内存 copy。&lt;/li>
&lt;li>上层的业务逻辑/编解码 均在虚拟连接上完成，上层逻辑可以异步独立并行执行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Shared map&lt;/p>
&lt;ul>
&lt;li>引入分片锁来减少锁力度。&lt;/li>
&lt;li>在调用端使用 sequence id 来标记请求，并使用分片锁存储 id 对应的回调。&lt;/li>
&lt;li>在接收响应数据后，根据 sequence id 来找到对应回调并执行。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>协议分包和编码&lt;/p>
&lt;ul>
&lt;li>如何识别完整的请求响应数据包是连接多路复用方案可行的关键，因此需要引入协议。&lt;/li>
&lt;li>这里采用 thrift header protocol 协议，通过消息头判断数据包完整性，通过 sequence id 标记请求和响应的对应关系。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="zerocopy">ZeroCopy&lt;/h2>
&lt;p>这里所说的 ZeroCopy，指的是 Linux 所提供的 ZeroCopy 的能力。上一章中我们说了业务层的零拷贝，而众所周知，当我们调用 sendmsg 系统调用发包的时候，实际上仍然是会产生一次数据的拷贝的，并且在大包场景下这个拷贝的消耗非常明显。以 100M 为例，perf 可以看到如下结果： &lt;br/>&lt;br>
&lt;img src="/img/blog/bytedance_gonet_practice_img/perf.png" alt="image">&lt;br>
&lt;br/>
这还仅仅是普通 tcp 发包的占用，在我们的场景下，大部分服务都会接入 Service Mesh，所以在一次发包中，一共会有 3 次拷贝：业务进程到内核、内核到 sidecar、sidecar 再到内核。这使得有大包需求的业务，拷贝所导致的 cpu 占用会特别明显，如下图：&lt;br>
&lt;br/>
&lt;img src="/img/blog/bytedance_gonet_practice_img/cpu.png" alt="image">&lt;br>
&lt;br/>
为了解决这个问题，我们选择了使用 Linux 提供的 ZeroCopy API（在 4.14 以后支持 send；5.4 以后支持 receive）。但是这引入了一个额外的工程问题：ZeroCopy send API 和原先调用方式不兼容，无法很好地共存。这里简单介绍一下 ZeroCopy send 的工作方式：业务进程调用 sendmsg 之后，sendmsg 会记录下 iovec 的地址并立即返回，这时候业务进程不能释放这段内存，需要通过 epoll 等待内核回调一个信号表明某段 iovec 已经发送成功之后才能释放。由于我们并不希望更改业务方的使用方法，需要对上层提供同步收发的接口，所以很难基于现有的 API 同时提供 ZeroCopy 和非 ZeroCopy 的抽象；而由于 ZeroCopy 在小包场景下是有性能损耗的，所以也不能将这个作为默认的选项。&lt;/p>
&lt;p>于是，字节跳动框架组和字节跳动内核组合作，由内核组提供了同步的接口：当调用 sendmsg 的时候，内核会监听并拦截内核原先给业务的回调，并且在回调完成后才会让 sendmsg 返回。这使得我们无需更改原有模型，可以很方便地接入 ZeroCopy send。同时，字节跳动内核组还实现了基于 unix domain socket 的 ZeroCopy，可以使得业务进程与 Mesh sidecar 之间的通信也达到零拷贝。&lt;/p>
&lt;p>在使用了 ZeroCopy send 后，perf 可以看到内核不再有 copy 的占用：&lt;br>
&lt;br/>
&lt;img src="/img/blog/bytedance_gonet_practice_img/perf2.png" alt="image">&lt;br>
&lt;br/>
从 cpu 占用数值上看，大包场景下 ZeroCopy 能够比非 ZeroCopy 节省一半的 cpu。&lt;/p>
&lt;h2 id="go-调度导致的延迟问题分享">Go 调度导致的延迟问题分享&lt;/h2>
&lt;p>在我们实践过程中，发现我们新写的 netpoll 虽然在 avg 延迟上表现胜于 Go 原生的 net 库，但是在 p99 和 max 延迟上要普遍略高于 Go 原生的 net 库，并且尖刺也会更加明显，如下图（Go 1.13，蓝色为 netpoll + 多路复用，绿色为 netpoll + 长连接，黄色为 net 库 + 长连接）：&lt;br>
&lt;br/>
&lt;img src="/img/blog/bytedance_gonet_practice_img/delay.png" alt="image">&lt;br>
&lt;br/>
我们尝试了很多种办法去优化，但是收效甚微。最终，我们定位出这个延迟并非是由于 netpoll 本身的开销导致的，而是由于 go 的调度导致的，比如说：&lt;/p>
&lt;ol>
&lt;li>由于在 netpoll 中，SubReactor 本身也是一个 goroutine，受调度影响，不能保证 EpollWait 回调之后马上执行，所以这一块会有延迟；&lt;/li>
&lt;li>同时，由于用来处理 I/O 事件的 SubReactor 和用来处理连接监听的 MainReactor 本身也是 goroutine，所以实际上很难保证在多核情况之下，这些 Reactor 能并行执行；甚至在最极端情况之下，可能这些 Reactor 会挂在同一个 P 下，最终变成了串行执行，无法充分利用多核优势；&lt;/li>
&lt;li>由于 EpollWait 回调之后，SubReactor 内是串行处理 I/O 事件的，导致排在最后的事件可能会有长尾问题；&lt;/li>
&lt;li>在连接多路复用场景下，由于每个连接绑定了一个 SubReactor，故延迟完全取决于这个 SubReactor 的调度，导致尖刺会更加明显。
由于 Go 在 runtime 中对于 net 库有做特殊优化，所以 net 库不会有以上情况；同时 net 库是 goroutine-per-connection 的模型，所以能确保请求能并行执行而不会相互影响。&lt;/li>
&lt;/ol>
&lt;p>对于以上这个问题，我们目前解决的思路有两个：&lt;/p>
&lt;ol>
&lt;li>修改 Go runtime 源码，在 Go runtime 中注册一个回调，每次调度时调用 EpollWait，把获取到的 fd 传递给回调执行；&lt;/li>
&lt;li>与字节跳动内核组合作，支持同时批量读/写多个连接，解决串行问题。另外，经过我们的测试，Go 1.14 能够使得延迟略有降低同时更加平稳，但是所能达到的极限 QPS 更低。希望我们的思路能够给业界同样遇到此问题的同学提供一些参考。&lt;/li>
&lt;/ol>
&lt;h2 id="后记">后记&lt;/h2>
&lt;p>希望以上的分享能够对社区有所帮助。同时，我们也在加速建设 netpoll 以及基于 netpoll 的新框架 Kitex。欢迎各位感兴趣的同学加入我们，共同建设 Go 语言生态！&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="http://man7.org/linux/man-pages/man7/epoll.7.html">http://man7.org/linux/man-pages/man7/epoll.7.html&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://golang.org/src/runtime/proc.go">https://golang.org/src/runtime/proc.go&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/panjf2000/gnet">https://github.com/panjf2000/gnet&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/tidwall/evio">https://github.com/tidwall/evio&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.0.5 版本发布</title><link>/zh/blog/2021/09/26/kitex-v0.0.5-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/09/26/kitex-v0.0.5-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="功能">功能:&lt;/h2>
&lt;ul>
&lt;li>增加默认的 ErrorHandler 封装 Error（用户指定会被覆盖）。&lt;/li>
&lt;li>metainfo 支持反向传递。&lt;/li>
&lt;li>支持了 JSON 泛化调用，使用指南可参考：&lt;a href="https://www.cloudwego.io/zh/docs/kitex/tutorials/advanced-feature/generic_call/">Kitex 泛化调用使用指南&lt;/a>。&lt;/li>
&lt;/ul>
&lt;h2 id="优化">优化:&lt;/h2>
&lt;ul>
&lt;li>多路复用场景下使用了新的 netpoll API 来改善吞吐和延迟。&lt;/li>
&lt;li>多路复用场景下支持 metainfo 的正向和反向传递。&lt;/li>
&lt;li>Client 会在需要的时候默认使用 RPCTimeout 中间件。&lt;/li>
&lt;li>连接池配置增加全局空闲连接和单实例空闲连接合法性校验。&lt;/li>
&lt;li>当更新 QPS 最大限制时会重置计数器。&lt;/li>
&lt;li>减小 QPS 限流的误差。&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复:&lt;/h2>
&lt;ul>
&lt;li>修复 WithExitWaitTime 没有正确设置退出等待时间的问题。&lt;/li>
&lt;li>修复更新 QPS 限制器更新间隔时，协程泄漏的问题。&lt;/li>
&lt;li>服务注册使用真实监听的地址。&lt;/li>
&lt;/ul>
&lt;h2 id="工具">工具:&lt;/h2>
&lt;ul>
&lt;li>修复了当 protobuf 文件只有 unary 方法时，生成出错的问题。&lt;/li>
&lt;/ul>
&lt;h2 id="文档">文档:&lt;/h2>
&lt;ul>
&lt;li>提供了英文版的README和其他文档。&lt;/li>
&lt;li>补充了泛化调用手册： &lt;a href="https://www.cloudwego.io/docs/kitex/tutorials/advanced-feature/generic_call/">English&lt;/a> | &lt;a href="https://www.cloudwego.io/zh/docs/kitex/tutorials/advanced-feature/generic_call/">中文&lt;/a>。&lt;/li>
&lt;li>README 中增加了 landsapce 和 roadmap。&lt;/li>
&lt;/ul>
&lt;h2 id="依赖变化">依赖变化:&lt;/h2>
&lt;ul>
&lt;li>github.com/cloudwego/netpoll: v0.0.3 -&amp;gt; v0.0.4&lt;/li>
&lt;li>github.com/bytedance/gopkg: v0.0.0-20210709064845-3c00f9323f09 -&amp;gt; v0.0.0-20210910103821-e4efae9c17c3&lt;/li>
&lt;/ul></description></item><item><title>Blog: 字节跳动 Go RPC 框架 Kitex 性能优化实践</title><link>/zh/blog/2021/09/23/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-go-rpc-%E6%A1%86%E6%9E%B6-kitex-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</link><pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/09/23/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8-go-rpc-%E6%A1%86%E6%9E%B6-kitex-%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</guid><description>
&lt;h2 id="前言">前言&lt;/h2>
&lt;p>Kitex 是字节跳动框架组研发的下一代高性能、强可扩展性的 Go RPC 框架。除具备丰富的服务治理特性外，相比其他框架还有以下特点：集成了自研的网络库 Netpoll；支持多消息协议（Thrift、Protobuf）和多交互方式（Ping-Pong、Oneway、 Streaming）；提供了更加灵活可扩展的代码生成器。&lt;/p>
&lt;p>目前公司内主要业务线都已经大范围使用 Kitex，据统计当前接入服务数量多达 8k。Kitex 推出后，我们一直在不断地优化性能，本文将分享我们在 Netpoll 和 序列化方面的优化工作。&lt;/p>
&lt;h2 id="自研网络库-netpoll-优化">自研网络库 Netpoll 优化&lt;/h2>
&lt;p>自研的基于 epoll 的网络库 —— Netpoll，在性能方面有了较为显著的优化。测试数据表明，当前版本(2020.12) 相比于上次分享时(2020.05)，吞吐能力 ↑30%，延迟 AVG ↓25%，TP99 ↓67%，性能已远超官方 net 库。以下，我们将分享两点显著提升性能的方案。&lt;/p>
&lt;h3 id="epoll_wait-调度延迟优化">epoll_wait 调度延迟优化&lt;/h3>
&lt;p>Netpoll 在刚发布时，遇到了延迟 AVG 较低，但 TP99 较高的问题。经过认真研究 epoll_wait，我们发现结合 polling 和 event trigger 两种模式，并优化调度策略，可以显著降低延迟。&lt;/p>
&lt;p>首先我们来看 Go 官方提供的 syscall.EpollWait 方法：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#204a87;font-weight:bold">func&lt;/span> &lt;span style="color:#000">EpollWait&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">epfd&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">events&lt;/span> &lt;span style="color:#000;font-weight:bold">[]&lt;/span>&lt;span style="color:#000">EpollEvent&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">msec&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">n&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#204a87;font-weight:bold">error&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里共提供 3 个参数，分别表示 epoll 的 fd、回调事件、等待时间，其中只有 msec 是动态可调的。&lt;/p>
&lt;p>通常情况下，我们主动调用 EpollWait 都会设置 msec=-1，即无限等待事件到来。事实上不少开源网络库也是这么做的。但是我们研究发现，msec=-1 并不是最优解。&lt;/p>
&lt;p>epoll_wait 内核源码(如下) 表明，msec=-1 比 msec=0 增加了 fetch_events 检查，因此耗时更长。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#000">static&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span> &lt;span style="color:#000">ep_poll&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000">eventpoll&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">ep&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000">epoll_event&lt;/span> &lt;span style="color:#000">__user&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">events&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">int&lt;/span> &lt;span style="color:#000">maxevents&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">long&lt;/span> &lt;span style="color:#000">timeout&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">timeout&lt;/span> &lt;span style="color:#000;font-weight:bold">&amp;gt;&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span> &lt;span style="color:#204a87;font-weight:bold">else&lt;/span> &lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">timeout&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">==&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">goto&lt;/span> &lt;span style="color:#000">send_events&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">fetch_events&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">eavail&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">goto&lt;/span> &lt;span style="color:#000">send_events&lt;/span>&lt;span style="color:#000;font-weight:bold">;&lt;/span>
&lt;span style="color:#000">send_events&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>Benchmark 表明，在有事件触发的情况下，msec=0 比 msec=-1 调用要快 18% 左右，因此在频繁事件触发场景下，使用 msec=0 调用明显是更优的。&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Benchmark&lt;/th>
&lt;th style="text-align:left">time/op&lt;/th>
&lt;th style="text-align:left">bytes/op&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">BenchmarkEpollWait, msec=0&lt;/td>
&lt;td style="text-align:left">270 ns/op&lt;/td>
&lt;td style="text-align:left">0 B/op&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkEpollWait, msec=-1&lt;/td>
&lt;td style="text-align:left">328 ns/op&lt;/td>
&lt;td style="text-align:left">0 B/op&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">EpollWait Delta&lt;/td>
&lt;td style="text-align:left">-17.68%&lt;/td>
&lt;td style="text-align:left">~&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>而在无事件触发的场景下，使用 msec=0 显然会造成无限轮询，空耗大量资源。&lt;/p>
&lt;p>综合考虑后，我们更希望在有事件触发时，使用 msec=0 调用，而在无事件时，使用 msec=-1 来减少轮询开销。伪代码如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#204a87;font-weight:bold">var&lt;/span> &lt;span style="color:#000">msec&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">n&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#000">syscall&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">EpollWait&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">epfd&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">events&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">msec&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">n&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;lt;=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">msec&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">continue&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">msec&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>那么这样就可以了吗？事实证明优化效果并不明显。&lt;/p>
&lt;p>我们再做思考：&lt;/p>
&lt;p>msec=0 仅单次调用耗时减少 50ns，影响太小，如果想要进一步优化，必须要在调度逻辑上做出调整。&lt;/p>
&lt;p>进一步思考：&lt;/p>
&lt;p>上述伪代码中，当无事件触发，调整 msec=-1 时，直接 continue 会立即再次执行 EpollWait，而由于无事件，msec=-1，当前 goroutine 会 block 并被 P 切换。但是被动切换效率较低，如果我们在 continue 前主动为 P 切换 goroutine，则可以节约时间。因此我们将上述伪代码改为如下：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#204a87;font-weight:bold">var&lt;/span> &lt;span style="color:#000">msec&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">for&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">n&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#000">syscall&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">EpollWait&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">epfd&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">events&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">msec&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">n&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;lt;=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">msec&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>
&lt;span style="color:#000">runtime&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Gosched&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">continue&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">msec&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>测试表明，调整代码后，吞吐量 ↑12%，TP99 ↓64%，获得了显著的延迟收益。&lt;/p>
&lt;h3 id="合理利用-unsafepointer">合理利用 unsafe.Pointer&lt;/h3>
&lt;p>继续研究 epoll_wait，我们发现 Go 官方对外提供的 syscall.EpollWait 和 runtime 自用的 epollwait 是不同的版本，即两者使用了不同的 EpollEvent。以下我们展示两者的区别：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#8f5902;font-style:italic">// @syscall
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">type&lt;/span> &lt;span style="color:#000">EpollEvent&lt;/span> &lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">Events&lt;/span> &lt;span style="color:#204a87;font-weight:bold">uint32&lt;/span>
&lt;span style="color:#000">Fd&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int32&lt;/span>
&lt;span style="color:#000">Pad&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int32&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#8f5902;font-style:italic">// @runtime
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">type&lt;/span> &lt;span style="color:#000">epollevent&lt;/span> &lt;span style="color:#204a87;font-weight:bold">struct&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">events&lt;/span> &lt;span style="color:#204a87;font-weight:bold">uint32&lt;/span>
&lt;span style="color:#000">data&lt;/span> &lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">8&lt;/span>&lt;span style="color:#000;font-weight:bold">]&lt;/span>&lt;span style="color:#204a87;font-weight:bold">byte&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// unaligned uintptr
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们看到，runtime 使用的 epollevent 是系统层 epoll 定义的原始结构；而对外版本则对其做了封装，将 epoll_data(epollevent.data) 拆分为固定的两字段：Fd 和 Pad。那么 runtime 又是如何使用的呢？在源码里我们看到这样的逻辑：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">**&lt;/span>&lt;span style="color:#000">pollDesc&lt;/span>&lt;span style="color:#000;font-weight:bold">)(&lt;/span>&lt;span style="color:#000">unsafe&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Pointer&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ev&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">data&lt;/span>&lt;span style="color:#000;font-weight:bold">))&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#000">pd&lt;/span>
&lt;span style="color:#000">pd&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">**&lt;/span>&lt;span style="color:#000">pollDesc&lt;/span>&lt;span style="color:#000;font-weight:bold">)(&lt;/span>&lt;span style="color:#000">unsafe&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Pointer&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">ev&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">data&lt;/span>&lt;span style="color:#000;font-weight:bold">))&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>显然，runtime 使用 epoll_data(&amp;amp;ev.data) 直接存储了 fd 对应结构体(pollDesc)的指针，这样在事件触发时，可以直接找到结构体对象，并执行相应逻辑。而对外版本则由于只能获得封装后的 Fd 参数，因此需要引入额外的 Map 来增删改查结构体对象，这样性能肯定相差很多。&lt;/p>
&lt;p>所以我们果断抛弃了 syscall.EpollWait，转而仿照 runtime 自行设计了 EpollWait 调用，同样采用 unsafe.Pointer 存取结构体对象。测试表明，该方案下 吞吐量 ↑10%，TP99 ↓10%，获得了较为明显的收益。&lt;/p>
&lt;h2 id="thrift-序列化反序列化优化">Thrift 序列化/反序列化优化&lt;/h2>
&lt;p>序列化是指把数据结构或对象转换成字节序列的过程，反序列化则是相反的过程。RPC 在通信时需要约定好序列化协议，client 在发送请求前进行序列化，字节序列通过网络传输到 server，server 再反序列进行逻辑处理，完成一次 RPC 请求。Thrift 支持 Binary、Compact 和 JSON 序列化协议。目前公司内部使用的基本都是 Binary，这里只介绍 Binary 协议。&lt;/p>
&lt;p>Binary 采用 TLV 编码实现，即每个字段都由 TLV 结构来描述，TLV 意为：Type 类型， Lenght 长度，Value 值，Value 也可以是个 TLV 结构，其中 Type 和 Length 的长度固定，Value 的长度则由 Length 的值决定。TLV 编码结构简单清晰，并且扩展性较好，但是由于增加了 Type 和 Length，有额外的内存开销，特别是在大部分字段都是基本类型的情况下有不小的空间浪费。&lt;/p>
&lt;p>序列化和反序列的性能优化从大的方面来看可以从空间和时间两个维度进行优化。从兼容已有的 Binary 协议来看，空间上的优化似乎不太可行，只能从时间维度进行优化，包括：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>减少内存操作次数，包括内存分配和拷贝，尽量预分配内存，减少不必要的开销；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>减少函数调用次数，比如可调整代码结构和 inline 等手段进行优化；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="调研">调研&lt;/h3>
&lt;p>根据 go_serialization_benchmarks 的压测数据，我们找到了一些性能卓越的序列化方案进行调研，希望能够对我们的优化工作有所启发。&lt;/p>
&lt;p>通过对 protobuf、gogoprotobuf 和 Cap&amp;rsquo;n Proto 的分析，我们得出以下结论：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>网络传输中出于 IO 的考虑，都会尽量压缩传输数据，protobuf 采用了 Varint 编码在大部分场景中都有着不错的压缩效果；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>gogoprotobuf 采用预计算方式，在序列化时能够减少内存分配次数，进而减少了内存分配带来的系统调用、锁和 GC 等代价；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cap&amp;rsquo;n Proto 直接操作 buffer，也是减少了内存分配和内存拷贝（少了中间的数据结构），并且在 struct pointer 的设计中把固定长度类型数据和非固定长度类型数据分开处理，针对固定长度类型可以快速处理；&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>从兼容性考虑，不可能改变现有的 TLV 编码格式，因此数据压缩不太现实，但是 2 和 3 对我们的优化工作是有启发的，事实上我们也是采取了类似的思路。&lt;/p>
&lt;h3 id="思路">思路&lt;/h3>
&lt;h4 id="减少内存操作">减少内存操作&lt;/h4>
&lt;p>&lt;strong>buffer 管理&lt;/strong>&lt;/p>
&lt;p>无论是序列化还是反序列化，都是从一块内存拷贝数据到另一块内存，这就涉及到内存分配和内存拷贝操作，尽量避免内存操作可以减少不必要的系统调用、锁和 GC 等开销。&lt;/p>
&lt;p>事实上 Kitex 已经提供了 LinkBuffer 用于 buffer 的管理，LinkBuffer 设计上采用链式结构，由多个 block 组成，其中 block 是大小固定的内存块，构建对象池维护空闲 block，由此复用 block，减少内存占用和 GC。&lt;/p>
&lt;p>刚开始我们简单地采用 sync.Pool 来复用 netpoll 的 LinkBufferNode，但是这样仍然无法解决对于大包场景下的内存复用（大的 Node 不能回收，否则会导致内存泄漏）。目前我们改成了维护一组 sync.Pool，每组中的 buffer size 都不同，新建 block 时根据最接近所需 size 的 pool 中去获取，这样可以尽可能复用内存，从测试来看内存分配和 GC 优化效果明显。&lt;/p>
&lt;p>&lt;strong>string / binary 零拷贝&lt;/strong>&lt;/p>
&lt;p>对于有一些业务，比如视频相关的业务，会在请求或者返回中有一个很大的 Binary 二进制数据代表了处理后的视频或者图片数据，同时会有一些业务会返回很大的 String（如全文信息等）。这种场景下，我们通过火焰图看到的热点都在数据的 copy 上，那我们就想了，我们是否可以减少这种拷贝呢？&lt;/p>
&lt;p>答案是肯定的。既然我们底层使用的 Buffer 是个链表，那么就可以很容易地在链表中间插入一个节点。&lt;/p>
&lt;p>&lt;img src="/img/blog/buffer-linkerd-list.png" alt="!image">&lt;/p>
&lt;p>我们就采用了类似的思想，当序列化的过程中遇到了 string 或者 binary 的时候， 将这个节点的 buffer 分成两段，在中间原地插入用户的 string / binary 对应的 buffer，这样可以避免大的 string / binary 的拷贝了。&lt;/p>
&lt;p>这里再介绍一下，如果我们直接用 []byte(string) 去转换一个 string 到 []byte 的话实际上是会发生一次拷贝的，原因是 Go 的设计中 string 是 immutable 的但是 []byte 是 mutable 的，所以这么转换的时候会拷贝一次；如果要不拷贝转换的话，就需要用到 unsafe 了：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#204a87;font-weight:bold">func&lt;/span> &lt;span style="color:#000">StringToSliceByte&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">s&lt;/span> &lt;span style="color:#204a87;font-weight:bold">string&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000;font-weight:bold">[]&lt;/span>&lt;span style="color:#204a87;font-weight:bold">byte&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">l&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#204a87">len&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">s&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000;font-weight:bold">[]&lt;/span>&lt;span style="color:#204a87;font-weight:bold">byte&lt;/span>&lt;span style="color:#000;font-weight:bold">)(&lt;/span>&lt;span style="color:#000">unsafe&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Pointer&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">reflect&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">SliceHeader&lt;/span>&lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">Data&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">reflect&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">StringHeader&lt;/span>&lt;span style="color:#000;font-weight:bold">)(&lt;/span>&lt;span style="color:#000">unsafe&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Pointer&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#000">s&lt;/span>&lt;span style="color:#000;font-weight:bold">))).&lt;/span>&lt;span style="color:#000">Data&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#000">Len&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#000">l&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#000">Cap&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span> &lt;span style="color:#000">l&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>
&lt;span style="color:#000;font-weight:bold">}))&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这段代码的意思是，先把 string 的地址拿到，再拼装上一个 slice byte 的 header，这样就可以不拷贝数据而将 string 转换成 []byte 了，不过要注意这样生成的 []byte 不可写，否则行为未定义。&lt;/p>
&lt;p>&lt;strong>预计算&lt;/strong>&lt;br>
线上存在某些服务有大包传输的场景，这种场景下会引入不小的序列化 / 反序列化开销。一般大包都是容器类型的大小非常大导致的，如果能够提前计算出 buffer，一些 O(n) 的操作就能降到 O(1)，减少了函数调用次数，在大包场景下也大量减少了内存分配的次数，带来的收益是可观的。&lt;/p>
&lt;ul>
&lt;li>
&lt;p>基本类型&lt;/p>
&lt;ul>
&lt;li>如果容器元素为基本类型（bool, byte, i16, i32, i64, double）的话，由于基本类型大小固定，在序列化时是可以提前计算出总的大小，并且一次性分配足够的 buffer，O(n) 的 malloc 操作次数可以降到 O(1)，从而大量减少了 malloc 的次数，同理在反序列化时可以减少 next 的操作次数。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>struct 字段重排&lt;/p>
&lt;ul>
&lt;li>
&lt;p>上面的优化只能针对容器元素类型为基本类型的有效，那么对于元素类型为 struct 的是否也能优化呢？答案是肯定的。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>沿用上面的思路，假如 struct 中如果存在基本类型的 field，也可以预先计算出这些 field 的大小，在序列化时为这些 field 提前分配 buffer，写的时候也把这些 field 顺序统一放到前面写，这样也能在一定程度上减少 malloc 的次数。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>一次性计算&lt;/p>
&lt;ul>
&lt;li>上面提到的是基本类型的优化，如果在序列化时，先遍历一遍 request 所有 field，便可以计算得到整个 request 的大小，提前分配好 buffer，在序列化和反序列时直接操作 buffer，这样对于非基本类型也能有优化效果。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>定义新的 codec 接口：&lt;/p>
&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#204a87;font-weight:bold">type&lt;/span> &lt;span style="color:#000">thriftMsgFastCodec&lt;/span> &lt;span style="color:#204a87;font-weight:bold">interface&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">BLength&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// count length of whole req/resp
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#000">FastWrite&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span> &lt;span style="color:#000;font-weight:bold">[]&lt;/span>&lt;span style="color:#204a87;font-weight:bold">byte&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span>
&lt;span style="color:#000">FastRead&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span> &lt;span style="color:#000;font-weight:bold">[]&lt;/span>&lt;span style="color:#204a87;font-weight:bold">byte&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#204a87;font-weight:bold">int&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#204a87;font-weight:bold">error&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>在 Marshal 和 Unmarshal 接口中做相应改造：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#204a87;font-weight:bold">func&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">c&lt;/span> &lt;span style="color:#000">thriftCodec&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000">Marshal&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">ctx&lt;/span> &lt;span style="color:#000">context&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Context&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">message&lt;/span> &lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Message&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">out&lt;/span> &lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">ByteBuffer&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#204a87;font-weight:bold">error&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">msg&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">ok&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">data&lt;/span>&lt;span style="color:#000;font-weight:bold">.(&lt;/span>&lt;span style="color:#000">thriftMsgFastCodec&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span> &lt;span style="color:#000">ok&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">msgBeginLen&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">MessageBeginLength&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">methodName&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">thrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">TMessageType&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">msgType&lt;/span>&lt;span style="color:#000;font-weight:bold">),&lt;/span> &lt;span style="color:#204a87">int32&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">seqID&lt;/span>&lt;span style="color:#000;font-weight:bold">))&lt;/span>
&lt;span style="color:#000">msgEndLen&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">MessageEndLength&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">out&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Malloc&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">msgBeginLen&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+&lt;/span> &lt;span style="color:#000">msg&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">BLength&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+&lt;/span> &lt;span style="color:#000">msgEndLen&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>&lt;span style="color:#8f5902;font-style:italic">// malloc once
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">!=&lt;/span> &lt;span style="color:#204a87;font-weight:bold">nil&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#000">perrors&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">NewProtocolErrorWithMsg&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">fmt&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Sprintf&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;thrift marshal, Malloc failed: %s&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Error&lt;/span>&lt;span style="color:#000;font-weight:bold">()))&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">WriteMessageBegin&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">methodName&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">thrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">TMessageType&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">msgType&lt;/span>&lt;span style="color:#000;font-weight:bold">),&lt;/span> &lt;span style="color:#204a87">int32&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">seqID&lt;/span>&lt;span style="color:#000;font-weight:bold">))&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">msg&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">FastWrite&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:])&lt;/span>
&lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">WriteMessageEnd&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:])&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#204a87;font-weight:bold">nil&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">func&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">c&lt;/span> &lt;span style="color:#000">thriftCodec&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000">Unmarshal&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">ctx&lt;/span> &lt;span style="color:#000">context&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Context&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">message&lt;/span> &lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Message&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">in&lt;/span> &lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">ByteBuffer&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#204a87;font-weight:bold">error&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#000">data&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">message&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Data&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">msg&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">ok&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">data&lt;/span>&lt;span style="color:#000;font-weight:bold">.(&lt;/span>&lt;span style="color:#000">thriftMsgFastCodec&lt;/span>&lt;span style="color:#000;font-weight:bold">);&lt;/span> &lt;span style="color:#000">ok&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">&amp;amp;&amp;amp;&lt;/span> &lt;span style="color:#000">message&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">PayloadLen&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">!=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">msgBeginLen&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">MessageBeginLength&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">methodName&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">msgType&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">seqID&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#000">tProt&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">next&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">message&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">PayloadLen&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span> &lt;span style="color:#000">msgBeginLen&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">-&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">MessageEndLength&lt;/span>&lt;span style="color:#000;font-weight:bold">())&lt;/span> &lt;span style="color:#8f5902;font-style:italic">// next once
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span> &lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">!=&lt;/span> &lt;span style="color:#204a87;font-weight:bold">nil&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">NewTransError&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">PROTOCOL_ERROR&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Error&lt;/span>&lt;span style="color:#000;font-weight:bold">())&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">_&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#000">msg&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">FastRead&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">!=&lt;/span> &lt;span style="color:#204a87;font-weight:bold">nil&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">NewTransError&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">PROTOCOL_ERROR&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Error&lt;/span>&lt;span style="color:#000;font-weight:bold">())&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">err&lt;/span> &lt;span style="color:#000;font-weight:bold">=&lt;/span> &lt;span style="color:#000">tProt&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">ReadMessageEnd&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">err&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">!=&lt;/span> &lt;span style="color:#204a87;font-weight:bold">nil&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">NewTransError&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">remote&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">PROTOCOL_ERROR&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span> &lt;span style="color:#000">err&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Error&lt;/span>&lt;span style="color:#000;font-weight:bold">())&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">tProt&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Recycle&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#000">err&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>生成代码中也做相应改造：&lt;/li>
&lt;/ul>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#204a87;font-weight:bold">func&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">p&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">Demo&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000">BLength&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">l&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">l&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">StructBeginLength&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#4e9a06">&amp;#34;Demo&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">p&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">!=&lt;/span> &lt;span style="color:#204a87;font-weight:bold">nil&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">l&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">p&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">field1Length&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#000">l&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">p&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">field2Length&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#000">l&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">p&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">field3Length&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#ce5c00;font-weight:bold">...&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">l&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">FieldStopLength&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#000">l&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">StructEndLength&lt;/span>&lt;span style="color:#000;font-weight:bold">()&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#000">l&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">func&lt;/span> &lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">p&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">*&lt;/span>&lt;span style="color:#000">Demo&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#000">FastWrite&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span> &lt;span style="color:#000;font-weight:bold">[]&lt;/span>&lt;span style="color:#204a87;font-weight:bold">byte&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span> &lt;span style="color:#204a87;font-weight:bold">int&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">:=&lt;/span> &lt;span style="color:#0000cf;font-weight:bold">0&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">WriteStructBegin&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:],&lt;/span> &lt;span style="color:#4e9a06">&amp;#34;Demo&amp;#34;&lt;/span>&lt;span style="color:#000;font-weight:bold">)&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">if&lt;/span> &lt;span style="color:#000">p&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">!=&lt;/span> &lt;span style="color:#204a87;font-weight:bold">nil&lt;/span> &lt;span style="color:#000;font-weight:bold">{&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">p&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">fastWriteField2&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:])&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">p&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">fastWriteField4&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:])&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">p&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">fastWriteField1&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:])&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">p&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">fastWriteField3&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:])&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">WriteFieldStop&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:])&lt;/span>
&lt;span style="color:#000">offset&lt;/span> &lt;span style="color:#ce5c00;font-weight:bold">+=&lt;/span> &lt;span style="color:#000">bthrift&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">Binary&lt;/span>&lt;span style="color:#000;font-weight:bold">.&lt;/span>&lt;span style="color:#000">WriteStructEnd&lt;/span>&lt;span style="color:#000;font-weight:bold">(&lt;/span>&lt;span style="color:#000">buf&lt;/span>&lt;span style="color:#000;font-weight:bold">[&lt;/span>&lt;span style="color:#000">offset&lt;/span>&lt;span style="color:#000;font-weight:bold">:])&lt;/span>
&lt;span style="color:#204a87;font-weight:bold">return&lt;/span> &lt;span style="color:#000">offset&lt;/span>
&lt;span style="color:#000;font-weight:bold">}&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="使用-simd-优化-thrift-编码">使用 SIMD 优化 Thrift 编码&lt;/h4>
&lt;p>公司内广泛使用 list&amp;lt;i64/i32&amp;gt; 类型来承载 ID 列表，并且 list&amp;lt;i64/i32&amp;gt; 的编码方式十分符合向量化的规律，于是我们用了 SIMD 来优化 list&amp;lt;i64/i32&amp;gt; 的编码过程。&lt;/p>
&lt;p>我们使用了 avx2，优化后的结果比较显著，在大数据量下针对 i64 可以提升 6 倍性能，针对 i32 可以提升 12 倍性能；在小数据量下提升更明显，针对 i64 可以提升 10 倍，针对 i32 可以提升 20 倍。&lt;/p>
&lt;h4 id="减少函数调用">减少函数调用&lt;/h4>
&lt;p>&lt;strong>inline&lt;/strong>&lt;/p>
&lt;p>inline 是在编译期间将一个函数调用原地展开，替换成这个函数的实现，它可以减少函数调用的开销以提高程序的性能。&lt;/p>
&lt;p>在 Go 中并不是所有函数都能 inline，使用参数-gflags=&amp;quot;-m&amp;quot;运行进程，可显示被 inline 的函数。以下几种情况无法内联：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>包含循环的函数；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>包含以下内容的函数：闭包调用，select，for，defer，go 关键字创建的协程；&lt;/p>
&lt;/li>
&lt;li>
&lt;p>超过一定长度的函数，默认情况下当解析 AST 时，Go 申请了 80 个节点作为内联的预算。每个节点都会消耗一个预算。比如，a = a + 1 这行代码包含了 5 个节点：AS, NAME, ADD, NAME, LITERAL。当一个函数的开销超过了这个预算，就无法内联。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>编译时通过指定参数-l可以指定编译器对代码内联的强度（go 1.9+），不过这里不推荐大家使用，在我们的测试场景下是 buggy 的，无法正常运行：&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-go" data-lang="go">&lt;span style="color:#8f5902;font-style:italic">// The debug[&amp;#39;l&amp;#39;] flag controls the aggressiveness. Note that main() swaps level 0 and 1, making 1 the default and -l disable. Additional levels (beyond -l) may be buggy and are not supported.
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">// 0: disabled
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">// 1: 80-nodes leaf functions, oneliners, panic, lazy typechecking (default)
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">// 2: (unassigned)
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">// 3: (unassigned)
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">// 4: allow non-leaf functions
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>内联虽然可以减少函数调用的开销，但是也可能因为存在重复代码，从而导致 CPU 缓存命中率降低，所以并不能盲目追求过度的内联，需要结合 profile 结果来具体分析。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-bash" data-lang="bash">go &lt;span style="color:#204a87">test&lt;/span> -gcflags&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;-m=2&amp;#39;&lt;/span> -v -test.run TestNewCodec 2&amp;gt;&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep &lt;span style="color:#4e9a06">&amp;#34;function too complex&amp;#34;&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> wc -l
&lt;span style="color:#0000cf;font-weight:bold">48&lt;/span>
go &lt;span style="color:#204a87">test&lt;/span> -gcflags&lt;span style="color:#ce5c00;font-weight:bold">=&lt;/span>&lt;span style="color:#4e9a06">&amp;#39;-m=2 -l=4&amp;#39;&lt;/span> -v -test.run TestNewCodec 2&amp;gt;&lt;span style="color:#000;font-weight:bold">&amp;amp;&lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> grep &lt;span style="color:#4e9a06">&amp;#34;function too complex&amp;#34;&lt;/span> &lt;span style="color:#000;font-weight:bold">|&lt;/span> wc -l
&lt;span style="color:#0000cf;font-weight:bold">25&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>从上面的输出结果可以看出，加强内联程度确实减少了一些&amp;quot;function too complex&amp;quot;，看下 benchmark 结果：&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Benchmark&lt;/th>
&lt;th style="text-align:left">time/op&lt;/th>
&lt;th style="text-align:left">bytes/op&lt;/th>
&lt;th style="text-align:left">allocs/op&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">BenchmarkOldMarshal-4&lt;/td>
&lt;td style="text-align:left">309 µs ± 2%&lt;/td>
&lt;td style="text-align:left">218KB&lt;/td>
&lt;td style="text-align:left">11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkNewMarshal-4&lt;/td>
&lt;td style="text-align:left">310 µs ± 3%&lt;/td>
&lt;td style="text-align:left">218KB&lt;/td>
&lt;td style="text-align:left">11&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>上面开启最高程度的内联强度，确实消除了不少因为“function too complex”带来无法内联的函数，但是压测结果显示收益不太明显。&lt;/p>
&lt;h3 id="测试结果">测试结果&lt;/h3>
&lt;p>我们构建了基准测试来对比优化前后的性能，下面是测试结果。&lt;/p>
&lt;p>环境：Go 1.13.5 darwin/amd64 on a 2.5 GHz Intel Core i7 16GB&lt;/p>
&lt;p>&lt;strong>小包&lt;/strong>&lt;/p>
&lt;p>data size: 20KB&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Benchmark&lt;/th>
&lt;th style="text-align:left">time/op&lt;/th>
&lt;th style="text-align:left">bytes/op&lt;/th>
&lt;th style="text-align:left">allocs/op&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">BenchmarkOldMarshal-4&lt;/td>
&lt;td style="text-align:left">138 µs ± 3%&lt;/td>
&lt;td style="text-align:left">25.4KB&lt;/td>
&lt;td style="text-align:left">19&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkNewMarshal-4&lt;/td>
&lt;td style="text-align:left">29 µs ± 3%&lt;/td>
&lt;td style="text-align:left">26.4KB&lt;/td>
&lt;td style="text-align:left">11&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Marshal Delta&lt;/td>
&lt;td style="text-align:left">-78.97%&lt;/td>
&lt;td style="text-align:left">3.87%&lt;/td>
&lt;td style="text-align:left">-42.11%&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkOldUnmarshal-4&lt;/td>
&lt;td style="text-align:left">199 µs ± 3%&lt;/td>
&lt;td style="text-align:left">4720&lt;/td>
&lt;td style="text-align:left">1360&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkNewUnmarshal-4&lt;/td>
&lt;td style="text-align:left">94µs ± 5%&lt;/td>
&lt;td style="text-align:left">4700&lt;/td>
&lt;td style="text-align:left">1280&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Unmarshal Delta&lt;/td>
&lt;td style="text-align:left">-52.93%&lt;/td>
&lt;td style="text-align:left">-0.24%&lt;/td>
&lt;td style="text-align:left">-5.38%&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>大包&lt;/strong>&lt;/p>
&lt;p>data size: 6MB&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Benchmark&lt;/th>
&lt;th style="text-align:left">time/op&lt;/th>
&lt;th style="text-align:left">bytes/op&lt;/th>
&lt;th style="text-align:left">allocs/op&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">BenchmarkOldMarshal-4&lt;/td>
&lt;td style="text-align:left">58.7ms ± 5%&lt;/td>
&lt;td style="text-align:left">6.96MB&lt;/td>
&lt;td style="text-align:left">3350&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkNewMarshal-4&lt;/td>
&lt;td style="text-align:left">13.3ms ± 3%&lt;/td>
&lt;td style="text-align:left">6.84MB&lt;/td>
&lt;td style="text-align:left">10&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Marshal Delta&lt;/td>
&lt;td style="text-align:left">-77.30%&lt;/td>
&lt;td style="text-align:left">-1.71%&lt;/td>
&lt;td style="text-align:left">-99.64%&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkOldUnmarshal-4&lt;/td>
&lt;td style="text-align:left">56.6ms ± 3%&lt;/td>
&lt;td style="text-align:left">17.4MB&lt;/td>
&lt;td style="text-align:left">391000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkNewUnmarshal-4&lt;/td>
&lt;td style="text-align:left">26.8ms ± 5%&lt;/td>
&lt;td style="text-align:left">17.5MB&lt;/td>
&lt;td style="text-align:left">390000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Unmarshal Delta&lt;/td>
&lt;td style="text-align:left">-52.54%&lt;/td>
&lt;td style="text-align:left">0.09%&lt;/td>
&lt;td style="text-align:left">-0.37%&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="无拷贝序列化">无拷贝序列化&lt;/h2>
&lt;p>在一些 request 和 response 数据较大的服务中，序列化和反序列化的代价较高，有两种优化思路：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>如前文所述进行序列化和反序列化的优化&lt;/p>
&lt;/li>
&lt;li>
&lt;p>以无拷贝序列化的方式进行调用&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="调研-1">调研&lt;/h3>
&lt;p>通过无拷贝序列化进行 RPC 调用，最早出自 Kenton Varda 的 Cap&amp;rsquo;n Proto 项目，Cap&amp;rsquo;n Proto 提供了一套数据交换格式和对应的编解码库。&lt;/p>
&lt;p>Cap&amp;rsquo;n Proto 本质上是开辟一个 bytes slice 作为 buffer ，所有对数据结构的读写操作都是直接读写 buffer，读写完成后，在头部添加一些 buffer 的信息就可以直接发送，对端收到后即可读取，因为没有 Go 语言结构体作为中间存储，所有无需序列化这个步骤，反序列化亦然。&lt;/p>
&lt;p>简单总结下 Cap&amp;rsquo;n Proto 的特点：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>所有数据的读写都是在一段连续内存中&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将序列化操作前置，在数据 Get/Set 的同时进行编解码&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在数据交换格式中，通过 pointer（数据存储位置的 offset）机制，使得数据可以存储在连续内存的任意位置，进而使得结构体中的数据可以以任意顺序读写&lt;/p>
&lt;ul>
&lt;li>对于结构体的固定大小字段，通过重新排列，使得这些字段存储在一块连续内存中&lt;/li>
&lt;li>对于结构体的不定大小字段（如 list），则通过一个固定大小的 pointer 来表示，pointer 中存储了包括数据位置在内的一些信息&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>首先 Cap&amp;rsquo;n Proto 没有 Go 语言结构体作为中间载体，得以减少一次拷贝，然后 Cap&amp;rsquo;n Proto 是在一段连续内存上进行操作，编码数据的读写可以一次完成，因为这两个原因，使得 Cap' Proto 的性能表现优秀。&lt;/p>
&lt;p>下面是相同数据结构下 Thrift 和 Cap&amp;rsquo;n Proto 的 Benchmark，考虑到 Cap&amp;rsquo;n Proto 是将编解码操作前置了，所以对比的是包括数据初始化在内的完整过程，即结构体数据初始化+（序列化）+写入 buffer +从 buffer 读出+（反序列化）+从结构体读出数据。&lt;/p>
&lt;div class="highlight">&lt;pre style="background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-Thrift" data-lang="Thrift">&lt;span style="color:#204a87;font-weight:bold">struct&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">MyTest&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000;font-weight:bold">{&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">i64&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Num&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">2&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Ano&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Ano&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">3&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">list&lt;/span>&lt;span style="color:#000;font-weight:bold">&amp;lt;&lt;/span>&lt;span style="color:#204a87;font-weight:bold">i64&lt;/span>&lt;span style="color:#000;font-weight:bold">&amp;gt;&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Nums&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#8f5902;font-style:italic">// 长度131072 大小1MB
&lt;/span>&lt;span style="color:#8f5902;font-style:italic">&lt;/span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#204a87;font-weight:bold">struct&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Ano&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000;font-weight:bold">{&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#0000cf;font-weight:bold">1&lt;/span>&lt;span style="color:#000;font-weight:bold">:&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#204a87;font-weight:bold">i64&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline"> &lt;/span>&lt;span style="color:#000">Num&lt;/span>&lt;span style="color:#000;font-weight:bold">,&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">&lt;/span>&lt;span style="color:#000;font-weight:bold">}&lt;/span>&lt;span style="color:#f8f8f8;text-decoration:underline">
&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Benchmark&lt;/th>
&lt;th style="text-align:left">Iter&lt;/th>
&lt;th style="text-align:left">time/op&lt;/th>
&lt;th style="text-align:left">bytes/op&lt;/th>
&lt;th style="text-align:left">alloc/op&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">BenchmarkThriftReadWrite&lt;/td>
&lt;td style="text-align:left">172&lt;/td>
&lt;td style="text-align:left">6855840 ns/op&lt;/td>
&lt;td style="text-align:left">3154209 B/op&lt;/td>
&lt;td style="text-align:left">545 allocs/op&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">BenchmarkCapnpReadWrite&lt;/td>
&lt;td style="text-align:left">1500&lt;/td>
&lt;td style="text-align:left">844924 ns/op&lt;/td>
&lt;td style="text-align:left">2085713 B/op&lt;/td>
&lt;td style="text-align:left">9 allocs/op&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">ReadWrite Delta&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;td style="text-align:left">-87.68%&lt;/td>
&lt;td style="text-align:left">-33.88%&lt;/td>
&lt;td style="text-align:left">-98.35%&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>（反序列化）+读出数据，视包大小，Cap&amp;rsquo;n Proto 性能大约是 Thrift 的 8-9 倍。写入数据+（序列化），视包大小，Cap&amp;rsquo;n Proto 性能大约是 Thrift 的 2-8 倍。整体性能 Cap' Proto 性能大约是 Thrift 的 4-8 倍。&lt;/p>
&lt;p>前面说了 Cap&amp;rsquo;n Proto 的优势，下面总结一下 Cap&amp;rsquo;n Proto 存在的一些问题：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Cap&amp;rsquo;n Proto 的连续内存存储这一特性带来的一个问题：当对不定大小数据进行 resize ，且需要的空间大于原有空间时，只能在后面重新分配一块空间，导致原来数据的空间成为了一个无法去掉的 hole 。这个问题随着调用链路的不断 resize 会越来越严重，要解决只能在整个链路上严格约束：尽量避免对不定大小字段的 resize ，当不得不 resize 的时候，重新构建一个结构体并对数据进行深拷贝。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cap&amp;rsquo;n Proto 因为没有 Go 语言结构体作为中间载体，使得所有的字段都只能通过接口进行读写，用户体验较差。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="thrift-协议兼容的无拷贝序列化">Thrift 协议兼容的无拷贝序列化&lt;/h3>
&lt;p>Cap&amp;rsquo;n Proto 为了更好更高效地支持无拷贝序列化，使用了一套自研的编解码格式，但在现在 Thrift 和 ProtoBuf 占主流的环境中难以铺开。为了能在协议兼容的同时获得无拷贝序列化的性能，我们开始了 Thrift 协议兼容的无拷贝序列化的探索。&lt;/p>
&lt;p>Cap&amp;rsquo;n Proto 作为无拷贝序列化的标杆，那么我们就看看 Cap&amp;rsquo;n Proto 上的优化能否应用到 Thrift 上：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>自然是无拷贝序列化的核心，不使用 Go 语言结构体作为中间载体，减少一次拷贝。此优化点是协议无关的，能够适用于任何已有的协议，自然也能和 Thrift 协议兼容，但是从 Cap&amp;rsquo;n Proto 的使用上来看，用户体验还需要仔细打磨一下。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Cap&amp;rsquo;n Proto 是在一段连续内存上进行操作，编码数据的读写可以一次完成。Cap&amp;rsquo;n Proto 得以在连续内存上操作的原因：有 pointer 机制，数据可以存储在任意位置，允许字段可以以任意顺序写入而不影响解码。但是一方面，在连续内存上容易因为误操作，导致在 resize 的时候留下 hole，另一方面，Thrift 没有类似于 pointer 的机制，故而对数据布局有着更严格的要求。这里有两个思路：&lt;/p>
&lt;ul>
&lt;li>坚持在连续内存上进行操作，并对用户使用提出严格要求：1. resize 操作必须重新构建数据结构 2. 当存在结构体嵌套时，对字段写入顺序有着严格要求（可以想象为把一个存在嵌套的结构体从外往里展开，写入时需要按展开顺序写入），且因为 Binary 等 TLV 编码的关系，在每个嵌套开始写入时，需要用户主动声明（如 StartWriteFieldX）。&lt;/li>
&lt;li>不完全在连续内存上操作，局部内存连续，可变字段则单独分配一块内存，既然内存不是完全连续的，自然也无法做到一次写操作便完成输出。为了尽可能接近一次写完数据的性能，我们采取了一种链式 buffer 的方案，一方面当可变字段 resize 时只需替换链式 buffer 的一个节点，无需像 Cap&amp;rsquo;n Proto 一样重新构建结构体，另一方面在需要输出时无需像 Thrift 一样需要感知实际的结构，只要把整个链路上的 buffer 写入即可。&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>先总结下目前确定的两个点：1. 不使用 Go 语言结构体作为中间载体，通过接口直接操作底层内存，在 Get/Set 时完成编解码 2. 通过链式 buffer 存储数据&lt;/p>
&lt;p>然后让我们看下目前还有待解决的问题：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>不使用 Go 语言结构体后带来的用户体验劣化&lt;/p>
&lt;ul>
&lt;li>解决方案：改善 Get/Set 接口的使用体验，尽可能做到和 Go 语言结构体同等的易用&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Cap&amp;rsquo;n Proto 的 Binary Format 是针对无拷贝序列化场景专门设计的，虽然每次 Get 时都会进行一次解码，但是解码代价非常小。而 Thrift 的协议（以 Binary 为例），没有类似于 pointer 的机制，当存在多个不定大小字段或者存在嵌套时，必须顺序解析而无法直接通过计算偏移拿到字段数据所在的位置，而每次 Get 都进行顺序解析的代价过于高昂。&lt;/p>
&lt;ul>
&lt;li>解决方案：我们在表示结构体的时候，除了记录结构体的 buffer 节点，还加了一个索引，里面记录了每个不定大小字段开始的 buffer 节点的指针。下面是目前的无拷贝序列化方案与 FastRead/Write，在 4 核下的极限性能对比测试：&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">包大小&lt;/th>
&lt;th style="text-align:left">类型&lt;/th>
&lt;th style="text-align:left">QPS&lt;/th>
&lt;th style="text-align:left">TP90&lt;/th>
&lt;th style="text-align:left">TP99&lt;/th>
&lt;th style="text-align:left">TP999&lt;/th>
&lt;th style="text-align:left">CPU&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">1KB&lt;/td>
&lt;td style="text-align:left">无序列化&lt;/td>
&lt;td style="text-align:left">70,700&lt;/td>
&lt;td style="text-align:left">1 ms&lt;/td>
&lt;td style="text-align:left">3 ms&lt;/td>
&lt;td style="text-align:left">6 ms&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;/td>
&lt;td style="text-align:left">FastWrite/FastRead&lt;/td>
&lt;td style="text-align:left">82,490&lt;/td>
&lt;td style="text-align:left">1 ms&lt;/td>
&lt;td style="text-align:left">2 ms&lt;/td>
&lt;td style="text-align:left">4 ms&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">2KB&lt;/td>
&lt;td style="text-align:left">无序列化&lt;/td>
&lt;td style="text-align:left">65,000&lt;/td>
&lt;td style="text-align:left">1 ms&lt;/td>
&lt;td style="text-align:left">4 ms&lt;/td>
&lt;td style="text-align:left">9 ms&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;/td>
&lt;td style="text-align:left">FastWrite/FastRead&lt;/td>
&lt;td style="text-align:left">72,000&lt;/td>
&lt;td style="text-align:left">1 ms&lt;/td>
&lt;td style="text-align:left">2 ms&lt;/td>
&lt;td style="text-align:left">8 ms&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">4KB&lt;/td>
&lt;td style="text-align:left">无序列化&lt;/td>
&lt;td style="text-align:left">56,400&lt;/td>
&lt;td style="text-align:left">2 ms&lt;/td>
&lt;td style="text-align:left">5 ms&lt;/td>
&lt;td style="text-align:left">10 ms&lt;/td>
&lt;td style="text-align:left">380%&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;/td>
&lt;td style="text-align:left">FastWrite/FastRead&lt;/td>
&lt;td style="text-align:left">52,700&lt;/td>
&lt;td style="text-align:left">2 ms&lt;/td>
&lt;td style="text-align:left">4 ms&lt;/td>
&lt;td style="text-align:left">10 ms&lt;/td>
&lt;td style="text-align:left">380%&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">32KB&lt;/td>
&lt;td style="text-align:left">无序列化&lt;/td>
&lt;td style="text-align:left">27,400&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;/td>
&lt;td style="text-align:left">FastWrite/FastRead&lt;/td>
&lt;td style="text-align:left">19,500&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;td style="text-align:left">/&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">1MB&lt;/td>
&lt;td style="text-align:left">无序列化&lt;/td>
&lt;td style="text-align:left">986&lt;/td>
&lt;td style="text-align:left">53 ms&lt;/td>
&lt;td style="text-align:left">56 ms&lt;/td>
&lt;td style="text-align:left">59 ms&lt;/td>
&lt;td style="text-align:left">260%&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;/td>
&lt;td style="text-align:left">FastWrite/FastRead&lt;/td>
&lt;td style="text-align:left">942&lt;/td>
&lt;td style="text-align:left">55 ms&lt;/td>
&lt;td style="text-align:left">59 ms&lt;/td>
&lt;td style="text-align:left">62 ms&lt;/td>
&lt;td style="text-align:left">290%&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">10MB&lt;/td>
&lt;td style="text-align:left">无序列化&lt;/td>
&lt;td style="text-align:left">82&lt;/td>
&lt;td style="text-align:left">630 ms&lt;/td>
&lt;td style="text-align:left">640 ms&lt;/td>
&lt;td style="text-align:left">645 ms&lt;/td>
&lt;td style="text-align:left">240%&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;/td>
&lt;td style="text-align:left">FastWrite/FastRead&lt;/td>
&lt;td style="text-align:left">82&lt;/td>
&lt;td style="text-align:left">630 ms&lt;/td>
&lt;td style="text-align:left">640 ms&lt;/td>
&lt;td style="text-align:left">640 ms&lt;/td>
&lt;td style="text-align:left">270%&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>测试结果概述：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>小包场景，无序列化性能表现较差，约为 FastWrite/FastRead 的 85%。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>大包场景，无序列化性能表现较好，4K 以上的包较 FastWrite/FastRead 提升 7%-40%。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="后记">后记&lt;/h2>
&lt;p>希望以上的分享能够对社区有所帮助。同时，我们也在尝试 share memory-based IPC、io_uring、tcp zero copy 、RDMA 等，更好地提升 Kitex 性能；重点优化同机、同容器的通讯场景。欢迎各位感兴趣的同学加入我们，共同建设 Go 语言生态！&lt;/p>
&lt;h2 id="参考资料">参考资料&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://github.com/alecthomas/go_serialization_benchmarks">https://github.com/alecthomas/go_serialization_benchmarks&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://capnproto.org/">https://capnproto.org/&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://software.intel.com/content/www/us/en/develop/documentation/cpp-compiler-developer-guide-and-reference/top/compiler-reference/intrinsics/intrinsics-for-intel-advanced-vector-extensions-2/intrinsics-for-shuffle-operations-1/mm256-shuffle-epi8.html">Intel® C++ Compiler Classic Developer Guide and Reference&lt;/a>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Blog: Netpoll v0.0.4 版本发布</title><link>/zh/blog/2021/09/16/netpoll-v0.0.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Thu, 16 Sep 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/09/16/netpoll-v0.0.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="优化">优化:&lt;/h2>
&lt;ul>
&lt;li>默认支持 TCP_NODELAY&lt;/li>
&lt;li>支持在一个循环中读写&lt;/li>
&lt;li>返回 nocopy rw 的真实错误&lt;/li>
&lt;li>更改了循环策略的默认数量&lt;/li>
&lt;li>重新定义了 EventLoop.Serve arg: Listener -&amp;gt; net.Listener&lt;/li>
&lt;li>在 DisableGopool 中增加了API&lt;/li>
&lt;li>删除了读锁&lt;/li>
&lt;li>连接 Flush API 调整为阻塞的&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复:&lt;/h2>
&lt;ul>
&lt;li>设置剩余待读取大小。&lt;/li>
&lt;/ul></description></item><item><title>Blog: 字节跳动开源内部微服务中间件 CloudWeGo</title><link>/zh/blog/2021/09/07/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%BC%80%E6%BA%90%E5%86%85%E9%83%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6-cloudwego/</link><pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/09/07/%E5%AD%97%E8%8A%82%E8%B7%B3%E5%8A%A8%E5%BC%80%E6%BA%90%E5%86%85%E9%83%A8%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E9%97%B4%E4%BB%B6-cloudwego/</guid><description>
&lt;h2 id="开源背景">开源背景&lt;/h2>
&lt;p>&lt;a href="https://github.com/cloudwego">CloudWeGo&lt;/a> 是一套由字节跳动开源的、以 Go 语言为核心的、可快速构建企业级云原生架构的中间件集合，专注于微服务通信与治理，具备高性能、可扩展、高可靠的特点。&lt;/p>
&lt;p>字节跳动内部使用 Golang 作为主要的业务开发语言，我们支持着数万个 Golang 微服务的可靠通信，经过数量众多的微服务和海量流量的验证，我们已经有了较为成熟的微服务最佳实践，于是考虑将内部的实践开源出去丰富社区生态。但微服务相关的项目较多，每个项目单独开源对外部用户并不友好，为了更好地让大家聚焦于微服务，我们以 CloudWeGo 作为项目名，逐步将内部微服务体系的项目开源，内外统一使用开源库，各项目以开源库为主进行迭代。&lt;/p>
&lt;p>内外维护一套代码，统一迭代演进，是我们开源前明确的原则，但毕竟涉及到代码库的调整，我们要保证内部用户尽可能无感知的迁移到开源库，本着对内部和开源用户负责的态度，我们要先确认内部可以平滑过渡，所以开源时并未对外宣传。让我们欣慰的是，在未宣传的情况下，一个月内 Kitex 收获了 1.2k stars，Netpoll 收获了700+ stars。&lt;/p>
&lt;p>CloudWeGo 不仅仅是一个对外的开源项目，也是一个真实的超大规模企业级实践项目。&lt;/p>
&lt;p>我们希望通过 CloudWeGo 丰富云原生社区的 Golang 产品体系，助力其他企业快速构建云原生架构，也希望吸引外部开发者共建，促进面向多元场景支持的演进，丰富产品能力。&lt;/p>
&lt;p>因为 CloudWeGo 下的项目会依赖很多内部的基础工具库，我们也推动将内部常用的 Golang 基础工具库开源出去，统一在 &lt;a href="https://github.com/bytedance/gopkg">bytedance/gopkg&lt;/a> 维护。&lt;/p>
&lt;h2 id="cloudwego-开源项目">CloudWeGo 开源项目&lt;/h2>
&lt;p>CloudWeGo 第一批以 Kitex RPC 框架和 Netpoll 网络库为主开源四个项目。Kitex 和 Netpoll 开源前我们发布过两篇文章 &lt;a href="https://mp.weixin.qq.com/s/Xoaoiotl7ZQoG2iXo9_DWg">字节跳动 Go RPC 框架 Kitex 性能优化实践&lt;/a> 和 &lt;a href="https://mp.weixin.qq.com/s?__biz=MzI1MzYzMjE0MQ==&amp;amp;mid=2247485756&amp;amp;idx=1&amp;amp;sn=4d2712e4bfb9be27a790fa15159a7be1&amp;amp;chksm=e9d0c2dedea74bc8179af39888a5b2b99266587cad32744ad11092b91ec2e2babc74e69090e6&amp;amp;scene=21#wechat_redirect">字节跳动在 Go 网络库上的实践&lt;/a> 分享我们的实践，文章发布后大家都在关注我们什么时候开源，因为我们希望将成熟的实践开源出去，所以没有过早的推动开源。&lt;/p>
&lt;h3 id="kitex">Kitex&lt;/h3>
&lt;p>Kitex 是字节跳动内部的 Golang 微服务 RPC 框架，具有高性能、强可扩展的主要特点。在 Kitex 之前内部的 Golang 框架是 Kite，但 Kite 与 Thrift 深度耦合、生成代码逻辑重，很难从网络模型或编解码层面改造优化，继续支持新特性势必会造成代码越发臃肿迭代受阻问题，于是我们针对曾经的痛点设计了新的框架 Kitex。虽然 Kitex 是新框架，但已经在线上应用一年多，目前字节内部超过 50% 的 Golang 微服务使用 Kitex。&lt;/p>
&lt;p>以下简述 Kitex 的一些特性：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>高性能：网络传输模块 Kitex 默认集成了自研的网络库 Netpoll，性能相较使用 go net 有显著优势；除了网络库带来的性能收益，Kitex 对 Thrift 编解码也做了优化，详见 &lt;a href="https://mp.weixin.qq.com/s/Xoaoiotl7ZQoG2iXo9_DWg">优化实践&lt;/a>。关于性能数据可参考 &lt;a href="https://github.com/cloudwego/kitex-benchmark">kitex-benchmark&lt;/a>。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>扩展性：Kitex 设计上做了模块划分，提供了较多的扩展接口以及默认的扩展实现，使用者也可以根据需要自行定制扩展，更多扩展能力参见 &lt;a href="https://www.cloudwego.io/zh/docs/kitex/tutorials/framework-exten/">文档&lt;/a>。Kitex 也并未耦合 Netpoll，开发者也可以选择其它网络库扩展使用。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>消息协议：RPC 消息协议默认支持 Thrift、Kitex Protobuf、gRPC。Thrift 支持 Buffered 和 Framed 二进制协议；Kitex Protobuf 是 Kitex 自定义的 Protobuf 消息协议，协议格式类似 Thrift；gRPC 是对 gRPC 消息协议的支持，可以与 gRPC 互通。除此之外，使用者也可以扩展自己的消息协议。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>传输协议：传输协议封装消息协议进行 RPC 互通，传输协议可以额外透传元信息，用于服务治理，Kitex 支持的传输协议有 TTHeader、HTTP2。TTHeader 可以和 Thrift、Kitex Protobuf 结合使用；HTTP2 目前主要是结合 gRPC 协议使用，后续也会支持 Thrift。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>多消息类型：支持 PingPong、Oneway、双向 Streaming。其中 Oneway 目前只对 Thrift 协议支持，双向 Streaming 只对 gRPC 支持，后续会考虑支持 Thrift 的双向 Streaming。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>服务治理：支持服务注册/发现、负载均衡、熔断、限流、重试、监控、链路跟踪、日志、诊断等服务治理模块，大部分均已提供默认扩展，使用者可选择集成。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Kitex 内置代码生成工具，可支持生成 Thrift、Protobuf 以及脚手架代码。原生的 Thrift 代码由本次一起开源的 Thriftgo 生成，Kitex 对 Thrift 的优化由 Kitex Tool 作为插件支持。Protobuf 代码由 Kitex 作为官方 protoc 插件生成 ，目前暂未单独支持 Protobuf IDL 的解析和代码生成。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="netpoll">Netpoll&lt;/h3>
&lt;p>Netpoll 是字节跳动内部的 Golang 高性能、I/O 非阻塞的网络库，专注于 RPC 场景。&lt;/p>
&lt;p>RPC 通常有较重的处理逻辑（业务逻辑、编解码），耗时长，不能像 Redis 一样采用串行处理(必须异步)。而 Go 的标准库 net 设计了 BIO(Blocking I/O) 模式的 API，为了保证异步处理，RPC 框架设计上需要为每个连接都分配一个 goroutine，这在空闲连接较多时，产生大量的空闲 goroutine，增加调度开销。此外，&lt;a href="https://github.com/golang/go/blob/master/src/net/net.go">net.Conn&lt;/a> 没有提供检查连接活性的 API，很难设计出高效的连接池，池中的失效连接无法及时清理，复用低效。&lt;/p>
&lt;p>开源社区目前缺少专注于 RPC 方案的 Go 网络库。类似的项目如：&lt;a href="https://github.com/tidwall/evio">evio&lt;/a> , &lt;a href="https://github.com/panjf2000/gnet">gnet&lt;/a> 等，均面向 Redis, Haproxy 这样的场景。&lt;/p>
&lt;p>因此 Netpoll 应运而生，它借鉴了 evio 和 Netty 的优秀设计，具有出色的 &lt;a href="https://github.com/cloudwego/netpoll/blob/main/README_CN.md#%e6%80%a7%e8%83%bd">性能&lt;/a>，更适用于微服务架构。 同时，Netpoll 还提供了一些 &lt;a href="https://github.com/cloudwego/netpoll/blob/main/README_CN.md#%e7%89%b9%e6%80%a7">特性&lt;/a>，推荐在 RPC 框架中作为底层网络库。&lt;/p>
&lt;h3 id="thriftgo">Thriftgo&lt;/h3>
&lt;p>Thriftgo 是 Go 语言实现的 Thrift IDL 解析和代码生成器，支持完善的 Thrift IDL 语法和语义检查，相较 Apache Thrift 官方的 Golang 生成代码，Thriftgo 做了一些问题修复且支持插件机制，用户可根据需求自定义生成代码。&lt;/p>
&lt;p>Kitex 的代码生成工具就是 Thriftgo 的插件，CloudWeGo 近期也会开源另一个 Thriftgo 的插件 thrift-gen-validator，支持 IDL Validator，用于字段值校验，解决开发者需要自行实现代码校验逻辑的负担，弥补 Thrift 缺失的能力。&lt;/p>
&lt;p>Thriftgo 目前虽然仅支持生成 Golang Thrift 代码，但其定位是可支持各语言的 Thrift 代码生成，未来如果有需求，我们也会考虑生成其他语言的代码，同时我们也将尝试将其回馈至 Apache Thrift 社区。&lt;/p>
&lt;h3 id="netpoll-http2">Netpoll-http2&lt;/h3>
&lt;p>Netpoll-http2 是基于 Golang 标准库 golang.org/x/net/http2 的源码替换 go net 为 Netpoll，目前用于 Kitex 对 gRPC 协议的支持，对 HTTP2 有需求的外部开发者也可以使用此库。&lt;/p>
&lt;h2 id="内外版本维护">内外版本维护&lt;/h2>
&lt;p>完整的微服务体系离不开基础的云生态，无论在公有云、私有云还是基于自己的基础设施开发微服务，都需要搭建额外的服务以很好的支持微服务的治理，比如治理平台、监控、链路跟踪、注册/发现、配置中心、服务网格等，而且还存在一些定制的规范。字节跳动自然也有完善的内部服务支持微服务体系，但这些服务短期还无法开源，那 CloudWeGo 如何内外维护一套代码，统一迭代呢？&lt;/p>
&lt;p>CloudWeGo 下与内部生态没有耦合的项目，如 Netpoll，直接迁移到开源库，内部依赖调整为开源库。&lt;/p>
&lt;p>而需要集成治理能力融入微服务体系的 Kitex 则基于其扩展性，将内外部的代码做了拆分，Kitex 的核心代码迁移到开源库，内部库封装一层壳保证内部用户无感知升级。集成内部治理特性的模块则作为 Kitex 的扩展保留在内部库，同时对于一些新的特性也会优先在内部库支持，稳定后迁移到开源库。&lt;/p>
&lt;p>对于使用 Kitex 的开源用户，同样可以对 Kitex 进行扩展，将 Kitex 融入自己的微服务体系中，也希望开发者能贡献自己的扩展到 &lt;a href="https://github.com/kitex-contrib">kitex-contrib&lt;/a>，为更多用户提供便利。&lt;/p>
&lt;h2 id="未来展望">未来展望&lt;/h2>
&lt;p>&lt;strong>继续开源其他内部项目&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>我们会继续开源其他内部项目，如 HTTP 框架 Hertz、基于共享内存的 IPC 通信库 ShmIPC 等，提供更多场景的微服务需求支持。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>逐步开源经验证的、稳定的特性&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>CloudWeGo 的主要项目均为字节内部微服务提供支持，新的特性通常会在内部验证，相对成熟后我们会逐步开源出去，比如对 ShmIPC 的集成、无序列化、无生成代码的支持等等。&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>结合内外部用户需求，持续迭代&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>CloudWeGo 开源后除向内部提供支持外，我们也希望 CloudWeGo 能为外部用户提供良好的支持，帮助大家快速搭建自己的微服务体系，所以我们会面向内外部用户迭代。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>就开源一个月的反馈看，大家对 Protobuf 的诉求较为强烈。坦诚来说 Kitex 虽然支持多协议，但字节内部 RPC 通信协议是 Thrift，对 Protobuf 无论是 Kitex Protobuf 还是兼容 gRPC 更多的是支持少部分内部用户的需求，所以暂时未开展性能优化，生成代码也是直接使用 Protobuf 官方的二进制（gogo/protobuf 是基于生成代码优化 Protobuf 序列化性能的优秀开源库，但很遗憾该库目前是停止维护状态，所以 Kitex 并未选择 gogo），但鉴于大家强烈的诉求，我们会计划开展 Kitex 对 Protobuf 支持的性能优化。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>欢迎大家向 CloudWeGo 提交 issue 和 PR 共建 CloudWeGo，我们诚心期待更多的开发者加入，也期待 CloudWeGo 助力越来越多的企业快速构建云原生架构。如果企业客户想内部试用，我们可以排期提供专项技术支持和交流，欢迎入群咨询。&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="/img/blog/LarkGroup.png" alt="!image">&lt;/p></description></item><item><title>Blog: Kitex v0.0.4 版本发布</title><link>/zh/blog/2021/08/26/kitex-v0.0.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/08/26/kitex-v0.0.4-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="优化">优化:&lt;/h2>
&lt;ul>
&lt;li>transMetaHandler 在自定义 boundHandlers 之前执行，保证自定义 boundHandlers 可以拿到 RPCInfo 信息。&lt;/li>
&lt;li>TransError 暴露封装 error 的 typeID 用于支持自定义 Error 回传错误码。&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复:&lt;/h2>
&lt;ul>
&lt;li>复用 RPCInfo 不对 stats level 重置， 以修复在使用 netpollmux 时 metric 丢失问题。&lt;/li>
&lt;li>清理不存在节点的连接池。&lt;/li>
&lt;li>Streaming 中增加 Netpoll EOF 错误判断来清除冗余的 warning 日志。&lt;/li>
&lt;li>修改熔断错误统计类型，非 Ignorable 错误类型均做熔断统计，以修复开源版本熔断无法正确生效和内部版本在开启mesh后重试熔断无法生效问题。&lt;/li>
&lt;/ul>
&lt;h2 id="工具">工具:&lt;/h2>
&lt;ul>
&lt;li>调整了 Protobuf unary 方法的生成代码，来同时支持 Kitex Protobuf 和 gRPC。&lt;/li>
&lt;li>升级了 thriftgo 版本来修复 golint。&lt;/li>
&lt;li>修复了生成代码中的错误。&lt;/li>
&lt;li>修复了流生成的代码缺少传输选项的错误。&lt;/li>
&lt;/ul>
&lt;h2 id="文档">文档:&lt;/h2>
&lt;ul>
&lt;li>添加了 Golong 配置部分的文档以及 Golang 版本要求。&lt;/li>
&lt;li>更新了一些现有文档。&lt;/li>
&lt;li>添加了一些英文文档。&lt;/li>
&lt;/ul>
&lt;h2 id="依赖变化">依赖变化:&lt;/h2>
&lt;ol>
&lt;li>Thriftgo: v0.0.2-0.20210726073420-0145861fcd04 -&amp;gt; v0.1.2&lt;/li>
&lt;li>Netpoll: v0.0.2 -&amp;gt; v0.0.3&lt;/li>
&lt;/ol></description></item><item><title>Blog: Kitex v0.0.3 版本发布</title><link>/zh/blog/2021/08/01/kitex-v0.0.3-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/08/01/kitex-v0.0.3-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="bug-修复">Bug 修复:&lt;/h2>
&lt;ul>
&lt;li>防止连接池被覆盖。&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.0.2 版本发布</title><link>/zh/blog/2021/07/30/kitex-v0.0.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/07/30/kitex-v0.0.2-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;h2 id="优化">优化：&lt;/h2>
&lt;ul>
&lt;li>Kitex 在没有 tracer 时关闭 stats 分阶段耗时采集，避免无 Trace 时额外的性能消耗。&lt;/li>
&lt;li>Kitex client 默认使用连接池。&lt;/li>
&lt;/ul>
&lt;h2 id="bug-修复">Bug 修复:&lt;/h2>
&lt;ul>
&lt;li>修复了一个 lbcache 中 nil-pointer 的错误。&lt;/li>
&lt;li>修复了一个 retry 重试（Backup Request）中的 data race 问题。&lt;/li>
&lt;/ul>
&lt;h2 id="工具">工具:&lt;/h2>
&lt;ul>
&lt;li>Kitex 工具去掉默认生成的配置文件。&lt;/li>
&lt;li>Kitex 工具现在使用最新的 thriftgo API 以避免老版 API 在生成代码时的几个边角案例。&lt;/li>
&lt;li>Kitex 工具现在会检查代码中是否包含 go 命令，不再假设它的存在。感谢 @anqiansong 的贡献。&lt;/li>
&lt;/ul>
&lt;h2 id="文档">文档:&lt;/h2>
&lt;ul>
&lt;li>我们在这个版本中更新了一些文档。&lt;/li>
&lt;li>我们修改了一些拼写错误和错别字。感谢 @rleungx @Huangxuny1 @JeffreyBool 的贡献。&lt;/li>
&lt;/ul></description></item><item><title>Blog: Kitex v0.0.1 版本发布</title><link>/zh/blog/2021/07/12/kitex-v0.0.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</link><pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate><guid>/zh/blog/2021/07/12/kitex-v0.0.1-%E7%89%88%E6%9C%AC%E5%8F%91%E5%B8%83/</guid><description>
&lt;p>Kitex 项目初始化。&lt;/p></description></item></channel></rss>